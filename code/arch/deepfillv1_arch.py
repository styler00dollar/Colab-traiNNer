"""
networks.py (12-12-20)
https://github.com/avalonstrel/GatedConvolution_pytorch/blob/master/models/networks.py

sa_gan.py (13-12-20)
https://github.com/avalonstrel/GatedConvolution_pytorch/blob/master/models/sa_gan.py

spectral.py (13-12-20)
https://github.com/avalonstrel/GatedConvolution_pytorch/blob/master/models/spectral.py
"""

import torch
import numpy as np
import torch.nn.functional as F
import torch.nn as nn
import pytorch_lightning as pl


def get_pad(in_, ksize, stride, atrous=1):
    out_ = np.ceil(float(in_) / stride)
    return int(((out_ - 1) * stride + atrous * (ksize - 1) + 1 - in_) / 2)


class GatedConv2dWithActivation(pl.LightningModule):
    """
    Gated Convlution layer with activation (default activation:LeakyReLU)
    Params: same as conv2d
    Input: The feature from last layer "I"
    Output:\phi(f(I))*\sigmoid(g(I))
    """

    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        bias=True,
        batch_norm=True,
        activation=torch.nn.LeakyReLU(0.2, inplace=True),
    ):
        super(GatedConv2dWithActivation, self).__init__()
        self.batch_norm = batch_norm
        self.activation = activation
        self.conv2d = torch.nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
        )
        self.mask_conv2d = torch.nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
        )
        self.batch_norm2d = torch.nn.BatchNorm2d(out_channels)
        self.sigmoid = torch.nn.Sigmoid()

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)

    def gated(self, mask):
        # return torch.clamp(mask, -1, 1)
        return self.sigmoid(mask)

    def forward(self, input):
        x = self.conv2d(input)
        mask = self.mask_conv2d(input)
        if self.activation is not None:
            x = self.activation(x) * self.gated(mask)
        else:
            x = x * self.gated(mask)
        if self.batch_norm:
            return self.batch_norm2d(x)
        else:
            return x


class GatedDeConv2dWithActivation(pl.LightningModule):
    """
    Gated DeConvlution layer with activation (default activation:LeakyReLU)
    resize + conv
    Params: same as conv2d
    Input: The feature from last layer "I"
    Output:\phi(f(I))*\sigmoid(g(I))
    """

    def __init__(
        self,
        scale_factor,
        in_channels,
        out_channels,
        kernel_size,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        bias=True,
        batch_norm=True,
        activation=torch.nn.LeakyReLU(0.2, inplace=True),
    ):
        super(GatedDeConv2dWithActivation, self).__init__()
        self.conv2d = GatedConv2dWithActivation(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
            batch_norm,
            activation,
        )
        self.scale_factor = scale_factor

    def forward(self, input):
        # print(input.size())
        x = F.interpolate(input, scale_factor=2)
        return self.conv2d(x)


class SNGatedConv2dWithActivation(pl.LightningModule):
    """
    Gated Convolution with spetral normalization
    """

    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        bias=True,
        batch_norm=True,
        activation=torch.nn.LeakyReLU(0.2, inplace=True),
    ):
        super(SNGatedConv2dWithActivation, self).__init__()
        self.conv2d = torch.nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
        )
        self.mask_conv2d = torch.nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
        )
        self.activation = activation
        self.batch_norm = batch_norm
        self.batch_norm2d = torch.nn.BatchNorm2d(out_channels)
        self.sigmoid = torch.nn.Sigmoid()
        self.conv2d = torch.nn.utils.spectral_norm(self.conv2d)
        self.mask_conv2d = torch.nn.utils.spectral_norm(self.mask_conv2d)
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)

    def gated(self, mask):
        return self.sigmoid(mask)
        # return torch.clamp(mask, -1, 1)

    def forward(self, input):
        x = self.conv2d(input)
        mask = self.mask_conv2d(input)
        if self.activation is not None:
            x = self.activation(x) * self.gated(mask)
        else:
            x = x * self.gated(mask)
        if self.batch_norm:
            return self.batch_norm2d(x)
        else:
            return x


class SNGatedDeConv2dWithActivation(pl.LightningModule):
    """
    Gated DeConvlution layer with activation (default activation:LeakyReLU)
    resize + conv
    Params: same as conv2d
    Input: The feature from last layer "I"
    Output:\phi(f(I))*\sigmoid(g(I))
    """

    def __init__(
        self,
        scale_factor,
        in_channels,
        out_channels,
        kernel_size,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        bias=True,
        batch_norm=True,
        activation=torch.nn.LeakyReLU(0.2, inplace=True),
    ):
        super(SNGatedDeConv2dWithActivation, self).__init__()
        self.conv2d = SNGatedConv2dWithActivation(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
            batch_norm,
            activation,
        )
        self.scale_factor = scale_factor

    def forward(self, input):
        # print(input.size())
        x = F.interpolate(input, scale_factor=2)
        return self.conv2d(x)


class SNConvWithActivation(pl.LightningModule):
    """
    SN convolution for spetral normalization conv
    """

    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        bias=True,
        activation=torch.nn.LeakyReLU(0.2, inplace=True),
    ):
        super(SNConvWithActivation, self).__init__()
        self.conv2d = torch.nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            dilation,
            groups,
            bias,
        )
        self.conv2d = torch.nn.utils.spectral_norm(self.conv2d)
        self.activation = activation
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)

    def forward(self, input):
        x = self.conv2d(input)
        if self.activation is not None:
            return self.activation(x)
        else:
            return x


import torch

from torch.nn import Parameter


def l2normalize(v, eps=1e-12):
    return v / (v.norm() + eps)


class SpectralNorm(pl.LightningModule):
    def __init__(self, module, name="weight", power_iterations=1):
        super(SpectralNorm, self).__init__()
        self.module = module
        self.name = name
        self.power_iterations = power_iterations
        if not self._made_params():
            self._make_params()

    def _update_u_v(self):
        u = getattr(self.module, self.name + "_u")
        v = getattr(self.module, self.name + "_v")
        w = getattr(self.module, self.name + "_bar")

        height = w.data.shape[0]
        for _ in range(self.power_iterations):
            v.data = l2normalize(torch.mv(torch.t(w.view(height, -1).data), u.data))
            u.data = l2normalize(torch.mv(w.view(height, -1).data, v.data))

        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))
        sigma = u.dot(w.view(height, -1).mv(v))
        setattr(self.module, self.name, w / sigma.expand_as(w))

    def _made_params(self):
        try:
            getattr(self.module, self.name + "_u")
            getattr(self.module, self.name + "_v")
            getattr(self.module, self.name + "_bar")
            return True
        except AttributeError:
            return False

    def _make_params(self):
        w = getattr(self.module, self.name)

        height = w.data.shape[0]
        width = w.view(height, -1).data.shape[1]

        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)
        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)
        u.data = l2normalize(u.data)
        v.data = l2normalize(v.data)
        w_bar = Parameter(w.data)

        del self.module._parameters[self.name]

        self.module.register_parameter(self.name + "_u", u)
        self.module.register_parameter(self.name + "_v", v)
        self.module.register_parameter(self.name + "_bar", w_bar)

    def forward(self, *args):
        self._update_u_v()
        return self.module.forward(*args)


import torch


# from .spectral import SpectralNorm
# from .networks import GatedConv2dWithActivation, GatedDeConv2dWithActivation, SNConvWithActivation, get_pad
class Self_Attn(pl.LightningModule):
    """Self attention Layer"""

    def __init__(self, in_dim, activation, with_attn=False):
        super(Self_Attn, self).__init__()
        self.chanel_in = in_dim
        self.activation = activation
        self.with_attn = with_attn
        self.query_conv = nn.Conv2d(
            in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1
        )
        self.key_conv = nn.Conv2d(
            in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1
        )
        self.value_conv = nn.Conv2d(
            in_channels=in_dim, out_channels=in_dim, kernel_size=1
        )
        self.gamma = nn.Parameter(torch.zeros(1))

        self.softmax = nn.Softmax(dim=-1)  #

    def forward(self, x):
        """
        inputs :
            x : input feature maps( B X C X W X H)
        returns :
            out : self attention value + input feature
            attention: B X N X N (N is Width*Height)
        """
        m_batchsize, C, width, height = x.size()
        proj_query = (
            self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1)
        )  # B X CX(N)
        proj_key = self.key_conv(x).view(
            m_batchsize, -1, width * height
        )  # B X C x (*W*H)
        energy = torch.bmm(proj_query, proj_key)  # transpose check
        attention = self.softmax(energy)  # BX (N) X (N)
        proj_value = self.value_conv(x).view(
            m_batchsize, -1, width * height
        )  # B X C X N

        out = torch.bmm(proj_value, attention.permute(0, 2, 1))
        out = out.view(m_batchsize, C, width, height)

        out = self.gamma * out + x
        if self.with_attn:
            return out, attention
        else:
            return out


class SAGenerator(pl.LightningModule):
    """Generator."""

    def __init__(self, batch_size, image_size=64, z_dim=100, conv_dim=64):
        super(Generator, self).__init__()
        self.imsize = image_size
        layer1 = []
        layer2 = []
        layer3 = []
        last = []

        repeat_num = int(np.log2(self.imsize)) - 3
        mult = 2**repeat_num  # 8
        layer1.append(SpectralNorm(nn.ConvTranspose2d(z_dim, conv_dim * mult, 4)))
        layer1.append(nn.BatchNorm2d(conv_dim * mult))
        layer1.append(nn.ReLU())

        curr_dim = conv_dim * mult

        layer2.append(
            SpectralNorm(nn.ConvTranspose2d(curr_dim, int(curr_dim / 2), 4, 2, 1))
        )
        layer2.append(nn.BatchNorm2d(int(curr_dim / 2)))
        layer2.append(nn.ReLU())

        curr_dim = int(curr_dim / 2)

        layer3.append(
            SpectralNorm(nn.ConvTranspose2d(curr_dim, int(curr_dim / 2), 4, 2, 1))
        )
        layer3.append(nn.BatchNorm2d(int(curr_dim / 2)))
        layer3.append(nn.ReLU())

        if self.imsize == 64:
            layer4 = []
            curr_dim = int(curr_dim / 2)
            layer4.append(
                SpectralNorm(nn.ConvTranspose2d(curr_dim, int(curr_dim / 2), 4, 2, 1))
            )
            layer4.append(nn.BatchNorm2d(int(curr_dim / 2)))
            layer4.append(nn.ReLU())
            self.l4 = nn.Sequential(*layer4)
            curr_dim = int(curr_dim / 2)

        self.l1 = nn.Sequential(*layer1)
        self.l2 = nn.Sequential(*layer2)
        self.l3 = nn.Sequential(*layer3)

        last.append(nn.ConvTranspose2d(curr_dim, 3, 4, 2, 1))
        last.append(nn.Tanh())
        self.last = nn.Sequential(*last)

        self.attn1 = Self_Attn(128, "relu")
        self.attn2 = Self_Attn(64, "relu")

    def forward(self, z):
        z = z.view(z.size(0), z.size(1), 1, 1)
        out = self.l1(z)
        out = self.l2(out)
        out = self.l3(out)
        out, p1 = self.attn1(out)
        out = self.l4(out)
        out, p2 = self.attn2(out)
        out = self.last(out)

        return out, p1, p2


class InpaintSANet(pl.LightningModule):
    """
    Inpaint generator, input should be 5*256*256, where 3*256*256 is the masked image, 1*256*256 for mask, 1*256*256 is the guidence
    """

    def __init__(self, n_in_channel=5):
        super(InpaintSANet, self).__init__()
        cnum = 32
        self.coarse_net = nn.Sequential(
            # input is 5*256*256, but it is full convolution network, so it can be larger than 256
            GatedConv2dWithActivation(
                n_in_channel, cnum, 5, 1, padding=get_pad(256, 5, 1)
            ),
            # downsample 128
            GatedConv2dWithActivation(cnum, 2 * cnum, 4, 2, padding=get_pad(256, 4, 2)),
            GatedConv2dWithActivation(
                2 * cnum, 2 * cnum, 3, 1, padding=get_pad(128, 3, 1)
            ),
            # downsample to 64
            GatedConv2dWithActivation(
                2 * cnum, 4 * cnum, 4, 2, padding=get_pad(128, 4, 2)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            # atrous convlution
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=2, padding=get_pad(64, 3, 1, 2)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=4, padding=get_pad(64, 3, 1, 4)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=8, padding=get_pad(64, 3, 1, 8)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=16, padding=get_pad(64, 3, 1, 16)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            # Self_Attn(4*cnum, 'relu'),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            # upsample
            GatedDeConv2dWithActivation(
                2, 4 * cnum, 2 * cnum, 3, 1, padding=get_pad(128, 3, 1)
            ),
            # Self_Attn(2*cnum, 'relu'),
            GatedConv2dWithActivation(
                2 * cnum, 2 * cnum, 3, 1, padding=get_pad(128, 3, 1)
            ),
            GatedDeConv2dWithActivation(
                2, 2 * cnum, cnum, 3, 1, padding=get_pad(256, 3, 1)
            ),
            GatedConv2dWithActivation(
                cnum, cnum // 2, 3, 1, padding=get_pad(256, 3, 1)
            ),
            # Self_Attn(cnum//2, 'relu'),
            GatedConv2dWithActivation(
                cnum // 2, 3, 3, 1, padding=get_pad(128, 3, 1), activation=None
            ),
        )

        self.refine_conv_net = nn.Sequential(
            # input is 5*256*256
            GatedConv2dWithActivation(
                n_in_channel, cnum, 5, 1, padding=get_pad(256, 5, 1)
            ),
            # downsample
            GatedConv2dWithActivation(cnum, cnum, 4, 2, padding=get_pad(256, 4, 2)),
            GatedConv2dWithActivation(cnum, 2 * cnum, 3, 1, padding=get_pad(128, 3, 1)),
            # downsample
            GatedConv2dWithActivation(
                2 * cnum, 2 * cnum, 4, 2, padding=get_pad(128, 4, 2)
            ),
            GatedConv2dWithActivation(
                2 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=2, padding=get_pad(64, 3, 1, 2)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=4, padding=get_pad(64, 3, 1, 4)
            ),
            # Self_Attn(4*cnum, 'relu'),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=8, padding=get_pad(64, 3, 1, 8)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, dilation=16, padding=get_pad(64, 3, 1, 16)
            ),
        )
        self.refine_attn = Self_Attn(4 * cnum, "relu", with_attn=False)
        self.refine_upsample_net = nn.Sequential(
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            GatedConv2dWithActivation(
                4 * cnum, 4 * cnum, 3, 1, padding=get_pad(64, 3, 1)
            ),
            GatedDeConv2dWithActivation(
                2, 4 * cnum, 2 * cnum, 3, 1, padding=get_pad(128, 3, 1)
            ),
            GatedConv2dWithActivation(
                2 * cnum, 2 * cnum, 3, 1, padding=get_pad(128, 3, 1)
            ),
            GatedDeConv2dWithActivation(
                2, 2 * cnum, cnum, 3, 1, padding=get_pad(256, 3, 1)
            ),
            GatedConv2dWithActivation(
                cnum, cnum // 2, 3, 1, padding=get_pad(256, 3, 1)
            ),
            # Self_Attn(cnum, 'relu'),
            GatedConv2dWithActivation(
                cnum // 2, 3, 3, 1, padding=get_pad(256, 3, 1), activation=None
            ),
        )

    def forward(self, imgs, masks, img_exs=None):
        # Coarse
        # masked_imgs =  imgs * (1 - masks) + masks

        if img_exs is None:
            input_imgs = torch.cat([imgs, masks, torch.full_like(masks, 1.0)], dim=1)
        else:
            input_imgs = torch.cat(
                [imgs, img_exs, masks, torch.full_like(masks, 1.0)], dim=1
            )
        # print(input_imgs.size(), imgs.size(), masks.size())
        x = self.coarse_net(input_imgs)
        x = torch.clamp(x, -1.0, 1.0)
        coarse_x = x
        # Refine
        masked_imgs = imgs * (1 - masks) + coarse_x * masks
        if img_exs is None:
            input_imgs = torch.cat(
                [masked_imgs, masks, torch.full_like(masks, 1.0)], dim=1
            )
        else:
            input_imgs = torch.cat(
                [masked_imgs, img_exs, masks, torch.full_like(masks, 1.0)], dim=1
            )
        x = self.refine_conv_net(input_imgs)
        x = self.refine_attn(x)
        # print(x.size(), attention.size())
        x = self.refine_upsample_net(x)
        x = torch.clamp(x, -1.0, 1.0)

        return x, coarse_x
