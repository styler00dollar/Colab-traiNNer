{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RRDB (pth to onnx).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "V0BPZ2OU03Ae",
        "Bz--7Uq8FtQe"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsxYKkWLXju5"
      },
      "source": [
        "# Converting RRDB (pth to onnx)\n",
        "\n",
        "Taking a normal pytorch model (``.pth``) and converting it to ``.onnx``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIPB6KmEOPQW"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0BPZ2OU03Ae"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EfvO0fBULzf",
        "cellView": "form"
      },
      "source": [
        "#@title utils.py\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def resize_like(x, target, mode='bilinear'):\n",
        "    return F.interpolate(x, target.shape[-2:], mode=mode, align_corners=False)\n",
        "\n",
        "\n",
        "def list2nparray(lst, dtype=None):\n",
        "    \"\"\"fast conversion from nested list to ndarray by pre-allocating space\"\"\"\n",
        "    if isinstance(lst, np.ndarray):\n",
        "        return lst\n",
        "    assert isinstance(lst, (list, tuple)), 'bad type: {}'.format(type(lst))\n",
        "    assert lst, 'attempt to convert empty list to np array'\n",
        "    if isinstance(lst[0], np.ndarray):\n",
        "        dim1 = lst[0].shape\n",
        "        assert all(i.shape == dim1 for i in lst)\n",
        "        if dtype is None:\n",
        "            dtype = lst[0].dtype\n",
        "            assert all(i.dtype == dtype for i in lst), \\\n",
        "                'bad dtype: {} {}'.format(dtype, set(i.dtype for i in lst))\n",
        "    elif isinstance(lst[0], (int, float, complex, np.number)):\n",
        "        return np.array(lst, dtype=dtype)\n",
        "    else:\n",
        "        dim1 = list2nparray(lst[0])\n",
        "        if dtype is None:\n",
        "            dtype = dim1.dtype\n",
        "        dim1 = dim1.shape\n",
        "    shape = [len(lst)] + list(dim1)\n",
        "    rst = np.empty(shape, dtype=dtype)\n",
        "    for idx, i in enumerate(lst):\n",
        "        rst[idx] = i\n",
        "    return rst\n",
        "\n",
        "\n",
        "def get_img_list(path):\n",
        "    return sorted(list(Path(path).glob('*.png'))) + \\\n",
        "        sorted(list(Path(path).glob('*.jpg'))) + \\\n",
        "        sorted(list(Path(path).glob('*.jpeg')))\n",
        "\n",
        "\n",
        "def gen_miss(img, mask, output):\n",
        "\n",
        "    imgs = get_img_list(img)\n",
        "    masks = get_img_list(mask)\n",
        "    print('Total images:', len(imgs), len(masks))\n",
        "\n",
        "    out = Path(output)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for i, (img, mask) in tqdm(enumerate(zip(imgs, masks))):\n",
        "        path = out.joinpath('miss_%04d.png' % (i+1))\n",
        "        img = cv2.imread(str(img), cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(str(mask), cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, img.shape[:2][::-1])\n",
        "        mask = mask[..., np.newaxis]\n",
        "        miss = img * (mask > 127) + 255 * (mask <= 127)\n",
        "        cv2.imwrite(str(path), miss)\n",
        "\n",
        "def merge_imgs(dirs, output, row=1, gap=2, res=512):\n",
        "\n",
        "    image_list = [get_img_list(path) for path in dirs]\n",
        "    img_count = [len(image) for image in image_list]\n",
        "    print('Total images:', img_count)\n",
        "    assert min(img_count) > 0, 'Please check the path of empty folder.'\n",
        "\n",
        "    output_dir = Path(output)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    n_img = len(dirs)\n",
        "    row = row\n",
        "    column = (n_img - 1) // row + 1\n",
        "    print('Row:', row)\n",
        "    print('Column:', column)\n",
        "\n",
        "    for i, unit in tqdm(enumerate(zip(*image_list))):\n",
        "        name = output_dir.joinpath('merge_%04d.png' % i)\n",
        "        merge = np.ones([\n",
        "            res*row + (row+1)*gap, res*column + (column+1)*gap, 3], np.uint8) * 255\n",
        "        for j, img in enumerate(unit):\n",
        "            r = j // column\n",
        "            c = j - r * column\n",
        "            img = cv2.imread(str(img), cv2.IMREAD_COLOR)\n",
        "            if img.shape[:2] != (res, res):\n",
        "                img = cv2.resize(img, (res, res))\n",
        "            start_h, start_w = (r + 1) * gap + r * res, (c + 1) * gap + c * res\n",
        "            merge[start_h: start_h + res, start_w: start_w + res] = img\n",
        "        cv2.imwrite(str(name), merge)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbdN2xrNLe1B",
        "cellView": "form"
      },
      "source": [
        "#@title block.py\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from models.modules.architectures.convolutions.partialconv2d import PartialConv2d #TODO\n",
        "#from models.modules.architectures.convolutions.deformconv2d import DeformConv2d\n",
        "#from models.networks import weights_init_normal, weights_init_xavier, weights_init_kaiming, weights_init_orthogonal\n",
        "\n",
        "\n",
        "####################\n",
        "# Basic blocks\n",
        "####################\n",
        "\n",
        "# Swish activation funtion\n",
        "def swish_func(x, beta=1.0):\n",
        "    \"\"\"\n",
        "    \"Swish: a Self-Gated Activation Function\"\n",
        "    Searching for Activation Functions (https://arxiv.org/abs/1710.05941)\n",
        "    \n",
        "    If beta=1 applies the Sigmoid Linear Unit (SiLU) function element-wise\n",
        "    If beta=0, Swish becomes the scaled linear function (identity \n",
        "      activation) f(x) = x/2\n",
        "    As beta -> âˆž, the sigmoid component converges to approach a 0-1 function\n",
        "      (unit step), and multiplying that by x gives us f(x)=2max(0,x), which \n",
        "      is the ReLU multiplied by a constant factor of 2, so Swish becomes like \n",
        "      the ReLU function.\n",
        "    \n",
        "    Including beta, Swish can be loosely viewed as a smooth function that \n",
        "      nonlinearly interpolate between identity (linear) and ReLU function.\n",
        "      The degree of interpolation can be controlled by the model if beta is \n",
        "      set as a trainable parameter.\n",
        "    \n",
        "    Alt: 1.78718727865 * (x * sigmoid(x) - 0.20662096414)\n",
        "    \"\"\"\n",
        "    \n",
        "    # In-place implementation, may consume less GPU memory: \n",
        "    \"\"\" \n",
        "    result = x.clone()\n",
        "    torch.sigmoid_(beta*x)\n",
        "    x *= result\n",
        "    return x\n",
        "    #\"\"\"\n",
        "    \n",
        "    # Normal out-of-place implementation:\n",
        "    #\"\"\"\n",
        "    return x * torch.sigmoid(beta * x)\n",
        "    #\"\"\"\n",
        "    \n",
        "# Swish module\n",
        "class Swish(nn.Module):\n",
        "    \n",
        "    __constants__ = ['beta', 'slope', 'inplace']\n",
        "    \n",
        "    def __init__(self, beta=1.0, slope=1.67653251702, inplace=False):\n",
        "        \"\"\"\n",
        "        Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "        \"\"\"\n",
        "        super(Swish).__init__()\n",
        "        self.inplace = inplace\n",
        "        # self.beta = beta # user-defined beta parameter, non-trainable\n",
        "        # self.beta = beta * torch.nn.Parameter(torch.ones(1)) # learnable beta parameter, create a tensor out of beta\n",
        "        self.beta = torch.nn.Parameter(torch.tensor(beta)) # learnable beta parameter, create a tensor out of beta\n",
        "        self.beta.requiresGrad = True # set requiresGrad to true to make it trainable\n",
        "\n",
        "        self.slope = slope / 2 # user-defined \"slope\", non-trainable\n",
        "        # self.slope = slope * torch.nn.Parameter(torch.ones(1)) # learnable slope parameter, create a tensor out of slope\n",
        "        # self.slope = torch.nn.Parameter(torch.tensor(slope)) # learnable slope parameter, create a tensor out of slope\n",
        "        # self.slope.requiresGrad = True # set requiresGrad to true to true to make it trainable\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        # Disabled, using inplace causes:\n",
        "        # \"RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation\"\n",
        "        if self.inplace:\n",
        "            input.mul_(torch.sigmoid(self.beta*input))\n",
        "            return 2 * self.slope * input\n",
        "        else:\n",
        "            return 2 * self.slope * swish_func(input, self.beta)\n",
        "        \"\"\"\n",
        "        return 2 * self.slope * swish_func(input, self.beta)\n",
        "\n",
        "\n",
        "def act(act_type, inplace=True, neg_slope=0.2, n_prelu=1, beta=1.0):\n",
        "    # helper selecting activation\n",
        "    # neg_slope: for leakyrelu and init of prelu\n",
        "    # n_prelu: for p_relu num_parameters\n",
        "    # beta: for swish\n",
        "    act_type = act_type.lower()\n",
        "    if act_type == 'relu':\n",
        "        layer = nn.ReLU(inplace)\n",
        "    elif act_type == 'leakyrelu' or act_type == 'lrelu':\n",
        "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
        "    elif act_type == 'prelu':\n",
        "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
        "    elif act_type == 'Tanh' or act_type == 'tanh':  # [-1, 1] range output\n",
        "        layer = nn.Tanh()\n",
        "    elif act_type == 'sigmoid':  # [0, 1] range output\n",
        "        layer = nn.Sigmoid()\n",
        "    elif act_type == 'swish':\n",
        "        layer = Swish(beta=beta, inplace=inplace)\n",
        "    else:\n",
        "        raise NotImplementedError('activation layer [{:s}] is not found'.format(act_type))\n",
        "    return layer\n",
        "\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self, *kwargs):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x, *kwargs):\n",
        "        return x\n",
        "\n",
        "\n",
        "def norm(norm_type, nc):\n",
        "    \"\"\"Return a normalization layer\n",
        "    Parameters:\n",
        "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
        "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
        "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
        "    \"\"\"\n",
        "    norm_type = norm_type.lower()\n",
        "    if norm_type == 'batch':\n",
        "        layer = nn.BatchNorm2d(nc, affine=True)\n",
        "        # norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
        "    elif norm_type == 'instance':\n",
        "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
        "        # norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
        "    # elif norm_type == 'layer':\n",
        "    #     return lambda num_features: nn.GroupNorm(1, num_features)\n",
        "    elif norm_type == 'none':\n",
        "        def norm_layer(x): return Identity()\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [{:s}] is not found'.format(norm_type))\n",
        "    return layer\n",
        "\n",
        "\n",
        "def add_spectral_norm(module, use_spectral_norm=False):\n",
        "    \"\"\" Add spectral norm to any module passed if use_spectral_norm = True,\n",
        "    else, returns the original module without change\n",
        "    \"\"\"\n",
        "    if use_spectral_norm:\n",
        "        return nn.utils.spectral_norm(module)\n",
        "    return module\n",
        "\n",
        "\n",
        "def pad(pad_type, padding):\n",
        "    \"\"\"\n",
        "    helper selecting padding layer\n",
        "    if padding is 'zero', can be done with conv layers\n",
        "    \"\"\"\n",
        "    pad_type = pad_type.lower()\n",
        "    if padding == 0:\n",
        "        return None\n",
        "    if pad_type == 'reflect':\n",
        "        layer = nn.ReflectionPad2d(padding)\n",
        "    elif pad_type == 'replicate':\n",
        "        layer = nn.ReplicationPad2d(padding)\n",
        "    elif pad_type == 'zero':\n",
        "        layer = nn.ZeroPad2d(padding)\n",
        "    else:\n",
        "        raise NotImplementedError('padding layer [{:s}] is not implemented'.format(pad_type))\n",
        "    return layer\n",
        "\n",
        "\n",
        "def get_valid_padding(kernel_size, dilation):\n",
        "    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
        "    padding = (kernel_size - 1) // 2\n",
        "    return padding\n",
        "\n",
        "\n",
        "class ConcatBlock(nn.Module):\n",
        "    # Concat the output of a submodule to its input\n",
        "    def __init__(self, submodule):\n",
        "        super(ConcatBlock, self).__init__()\n",
        "        self.sub = submodule\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.cat((x, self.sub(x)), dim=1)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Identity .. \\n|' + self.sub.__repr__().replace('\\n', '\\n|')\n",
        "\n",
        "\n",
        "class ShortcutBlock(nn.Module):\n",
        "    # Elementwise sum the output of a submodule to its input\n",
        "    def __init__(self, submodule):\n",
        "        super(ShortcutBlock, self).__init__()\n",
        "        self.sub = submodule\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x + self.sub(x)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Identity + \\n|' + self.sub.__repr__().replace('\\n', '\\n|')\n",
        "\n",
        "\n",
        "def sequential(*args):\n",
        "    # Flatten Sequential. It unwraps nn.Sequential.\n",
        "    if len(args) == 1:\n",
        "        if isinstance(args[0], OrderedDict):\n",
        "            raise NotImplementedError('sequential does not support OrderedDict input.')\n",
        "        return args[0]  # No sequential is needed.\n",
        "    modules = []\n",
        "    for module in args:\n",
        "        if isinstance(module, nn.Sequential):\n",
        "            for submodule in module.children():\n",
        "                modules.append(submodule)\n",
        "        elif isinstance(module, nn.Module):\n",
        "            modules.append(module)\n",
        "    return nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "def conv_block(in_nc, out_nc, kernel_size, stride=1, dilation=1, groups=1, bias=True, \\\n",
        "               pad_type='zero', norm_type=None, act_type='relu', mode='CNA', convtype='Conv2D', \\\n",
        "               spectral_norm=False):\n",
        "    \"\"\"\n",
        "    Conv layer with padding, normalization, activation\n",
        "    mode: CNA --> Conv -> Norm -> Act\n",
        "        NAC --> Norm -> Act --> Conv (Identity Mappings in Deep Residual Networks, ECCV16)\n",
        "    \"\"\"\n",
        "    assert mode in ['CNA', 'NAC', 'CNAC'], 'Wrong conv mode [{:s}]'.format(mode)\n",
        "    padding = get_valid_padding(kernel_size, dilation)\n",
        "    p = pad(pad_type, padding) if pad_type and pad_type != 'zero' else None\n",
        "    padding = padding if pad_type == 'zero' else 0\n",
        "    \n",
        "    if convtype=='PartialConv2D':\n",
        "        c = PartialConv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "               dilation=dilation, bias=bias, groups=groups)\n",
        "    elif convtype=='DeformConv2D':\n",
        "        c = DeformConv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "               dilation=dilation, bias=bias, groups=groups)\n",
        "    elif convtype=='Conv3D':\n",
        "        c = nn.Conv3d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "                dilation=dilation, bias=bias, groups=groups)\n",
        "    else: #default case is standard 'Conv2D':\n",
        "        c = nn.Conv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "                dilation=dilation, bias=bias, groups=groups) #normal conv2d\n",
        "            \n",
        "    if spectral_norm:\n",
        "        c = nn.utils.spectral_norm(c)\n",
        "    \n",
        "    a = act(act_type) if act_type else None\n",
        "    if 'CNA' in mode:\n",
        "        #n = norm(norm_type, out_nc) if norm_type else None\n",
        "        n = None\n",
        "        return sequential(p, c, n, a)\n",
        "    elif mode == 'NAC':\n",
        "        if norm_type is None and act_type is not None:\n",
        "            a = act(act_type, inplace=False)\n",
        "            # Important!\n",
        "            # input----ReLU(inplace)----Conv--+----output\n",
        "            #        |________________________|\n",
        "            # inplace ReLU will modify the input, therefore wrong output\n",
        "        n = norm(norm_type, in_nc) if norm_type else None\n",
        "        return sequential(n, a, p, c)\n",
        "\n",
        "\n",
        "def make_layer(basic_block, num_basic_block, **kwarg):\n",
        "    \"\"\"Make layers by stacking the same blocks.\n",
        "    Args:\n",
        "        basic_block (nn.module): nn.module class for basic block. (block)\n",
        "        num_basic_block (int): number of blocks. (n_layers)\n",
        "    Returns:\n",
        "        nn.Sequential: Stacked blocks in nn.Sequential.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    for _ in range(num_basic_block):\n",
        "        layers.append(basic_block(**kwarg))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class Mean(nn.Module):\n",
        "  def __init__(self, dim: list, keepdim=False):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.keepdim = keepdim\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.mean(x, self.dim, self.keepdim)\n",
        "\n",
        "\n",
        "####################\n",
        "# initialize modules\n",
        "####################\n",
        "\n",
        "@torch.no_grad()\n",
        "def default_init_weights(module_list, init_type='kaiming', scale=1, bias_fill=0, **kwargs):\n",
        "    \"\"\"Initialize network weights.\n",
        "    Args:\n",
        "        module_list (list[nn.Module] | nn.Module): Modules to be initialized.\n",
        "        init_type (str): the type of initialization in: 'normal', 'kaiming' \n",
        "            or 'orthogonal'\n",
        "        scale (float): Scale initialized weights, especially for residual\n",
        "            blocks. Default: 1. (for 'kaiming')\n",
        "        bias_fill (float): The value to fill bias. Default: 0\n",
        "        kwargs (dict): Other arguments for initialization function:\n",
        "            mean and/or std for 'normal'.\n",
        "            a and/or mode for 'kaiming'\n",
        "            gain for 'orthogonal' and xavier\n",
        "    \"\"\"\n",
        "    \n",
        "    # TODO\n",
        "    # logger.info('Initialization method [{:s}]'.format(init_type))\n",
        "    if not isinstance(module_list, list):\n",
        "        module_list = [module_list]\n",
        "    for module in module_list:\n",
        "        for m in module.modules():\n",
        "            if init_type == 'normal':\n",
        "                weights_init_normal(m, bias_fill=bias_fill, **kwargs)\n",
        "            if init_type == 'xavier':\n",
        "                weights_init_xavier(m, scale=scale, bias_fill=bias_fill, **kwargs)    \n",
        "            elif init_type == 'kaiming':\n",
        "                weights_init_kaiming(m, scale=scale, bias_fill=bias_fill, **kwargs)\n",
        "            elif init_type == 'orthogonal':\n",
        "                weights_init_orthogonal(m, bias_fill=bias_fill)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [{:s}] not implemented'.format(init_type))\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# Upsampler\n",
        "####################\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    r\"\"\"Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\n",
        "\n",
        "    The input data is assumed to be of the form\n",
        "    `minibatch x channels x [optional depth] x [optional height] x width`.\n",
        "\n",
        "    Args:\n",
        "        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], optional):\n",
        "            output spatial sizes\n",
        "        scale_factor (float or Tuple[float] or Tuple[float, float] or Tuple[float, float, float], optional):\n",
        "            multiplier for spatial size. Has to match input size if it is a tuple.\n",
        "        mode (str, optional): the upsampling algorithm: one of ``'nearest'``,\n",
        "            ``'linear'``, ``'bilinear'``, ``'bicubic'`` and ``'trilinear'``.\n",
        "            Default: ``'nearest'``\n",
        "        align_corners (bool, optional): if ``True``, the corner pixels of the input\n",
        "            and output tensors are aligned, and thus preserving the values at\n",
        "            those pixels. This only has effect when :attr:`mode` is\n",
        "            ``'linear'``, ``'bilinear'``, or ``'trilinear'``. Default: ``False``\n",
        "    \"\"\"\n",
        "    # To prevent warning: nn.Upsample is deprecated\n",
        "    # https://discuss.pytorch.org/t/which-function-is-better-for-upsampling-upsampling-or-interpolate/21811/8\n",
        "    # From: https://pytorch.org/docs/stable/_modules/torch/nn/modules/upsampling.html#Upsample\n",
        "    # Alternative: https://discuss.pytorch.org/t/using-nn-function-interpolate-inside-nn-sequential/23588/2?u=ptrblck\n",
        "    \n",
        "    def __init__(self, size=None, scale_factor=None, mode=\"nearest\", align_corners=None):\n",
        "        super(Upsample, self).__init__()\n",
        "        if isinstance(scale_factor, tuple):\n",
        "            self.scale_factor = tuple(float(factor) for factor in scale_factor)\n",
        "        else:\n",
        "            self.scale_factor = float(scale_factor) if scale_factor else None\n",
        "        self.mode = mode\n",
        "        self.size = size\n",
        "        self.align_corners = align_corners\n",
        "        # self.interp = nn.functional.interpolate\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return nn.functional.interpolate(x, size=self.size, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
        "        # return self.interp(x, size=self.size, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
        "    \n",
        "    def extra_repr(self):\n",
        "        if self.scale_factor is not None:\n",
        "            info = 'scale_factor=' + str(self.scale_factor)\n",
        "        else:\n",
        "            info = 'size=' + str(self.size)\n",
        "        info += ', mode=' + self.mode\n",
        "        return info\n",
        "\n",
        "def pixelshuffle_block(in_nc, out_nc, upscale_factor=2, kernel_size=3, stride=1, bias=True, \\\n",
        "                        pad_type='zero', norm_type=None, act_type='relu', convtype='Conv2D'):\n",
        "    \"\"\"\n",
        "    Pixel shuffle layer\n",
        "    (Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional\n",
        "    Neural Network, CVPR17)\n",
        "    \"\"\"\n",
        "    conv = conv_block(in_nc, out_nc * (upscale_factor ** 2), kernel_size, stride, bias=bias, \\\n",
        "                        pad_type=pad_type, norm_type=None, act_type=None, convtype=convtype)\n",
        "    pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "    n = norm(norm_type, out_nc) if norm_type else None\n",
        "    a = act(act_type) if act_type else None\n",
        "    return sequential(conv, pixel_shuffle, n, a)\n",
        "\n",
        "def upconv_block(in_nc, out_nc, upscale_factor=2, kernel_size=3, stride=1, bias=True, \\\n",
        "                pad_type='zero', norm_type=None, act_type='relu', mode='nearest', convtype='Conv2D'):\n",
        "    \"\"\"\n",
        "    Upconv layer described in https://distill.pub/2016/deconv-checkerboard/\n",
        "    Example to replace deconvolutions: \n",
        "        - from: nn.ConvTranspose2d(in_nc, out_nc, kernel_size=4, stride=2, padding=1)\n",
        "        - to: upconv_block(in_nc, out_nc,kernel_size=3, stride=1, act_type=None)\n",
        "    \"\"\"\n",
        "    # upsample = nn.Upsample(scale_factor=upscale_factor, mode=mode)\n",
        "    upscale_factor = (1, upscale_factor, upscale_factor) if convtype == 'Conv3D' else upscale_factor\n",
        "    upsample = Upsample(scale_factor=upscale_factor, mode=mode) #Updated to prevent the \"nn.Upsample is deprecated\" Warning\n",
        "    conv = conv_block(in_nc, out_nc, kernel_size, stride, bias=bias, \\\n",
        "                        pad_type=pad_type, norm_type=norm_type, act_type=act_type, convtype=convtype)\n",
        "    return sequential(upsample, conv)\n",
        "\n",
        "# PPON\n",
        "def conv_layer(in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1):\n",
        "    padding = int((kernel_size - 1) / 2) * dilation\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, bias=True, dilation=dilation, groups=groups)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# ESRGANplus\n",
        "####################\n",
        "\n",
        "class GaussianNoise(nn.Module):\n",
        "    def __init__(self, sigma=0.1, is_relative_detach=False):\n",
        "        super().__init__()\n",
        "        self.sigma = sigma\n",
        "        self.is_relative_detach = is_relative_detach\n",
        "        self.noise = torch.tensor(0, dtype=torch.float).to(torch.device('cuda'))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training and self.sigma != 0:\n",
        "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
        "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
        "            x = x + sampled_noise\n",
        "        return x \n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "# TODO: Not used:\n",
        "# https://github.com/github-pengge/PyTorch-progressive_growing_of_gans/blob/master/models/base_model.py\n",
        "class minibatch_std_concat_layer(nn.Module):\n",
        "    def __init__(self, averaging='all'):\n",
        "        super(minibatch_std_concat_layer, self).__init__()\n",
        "        self.averaging = averaging.lower()\n",
        "        if 'group' in self.averaging:\n",
        "            self.n = int(self.averaging[5:])\n",
        "        else:\n",
        "            assert self.averaging in ['all', 'flat', 'spatial', 'none', 'gpool'], 'Invalid averaging mode'%self.averaging\n",
        "        self.adjusted_std = lambda x, **kwargs: torch.sqrt(torch.mean((x - torch.mean(x, **kwargs)) ** 2, **kwargs) + 1e-8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = list(x.size())\n",
        "        target_shape = copy.deepcopy(shape)\n",
        "        vals = self.adjusted_std(x, dim=0, keepdim=True)\n",
        "        if self.averaging == 'all':\n",
        "            target_shape[1] = 1\n",
        "            vals = torch.mean(vals, dim=1, keepdim=True)\n",
        "        elif self.averaging == 'spatial':\n",
        "            if len(shape) == 4:\n",
        "                vals = mean(vals, axis=[2,3], keepdim=True)             # torch.mean(torch.mean(vals, 2, keepdim=True), 3, keepdim=True)\n",
        "        elif self.averaging == 'none':\n",
        "            target_shape = [target_shape[0]] + [s for s in target_shape[1:]]\n",
        "        elif self.averaging == 'gpool':\n",
        "            if len(shape) == 4:\n",
        "                vals = mean(x, [0,2,3], keepdim=True)                   # torch.mean(torch.mean(torch.mean(x, 2, keepdim=True), 3, keepdim=True), 0, keepdim=True)\n",
        "        elif self.averaging == 'flat':\n",
        "            target_shape[1] = 1\n",
        "            vals = torch.FloatTensor([self.adjusted_std(x)])\n",
        "        else:                                                           # self.averaging == 'group'\n",
        "            target_shape[1] = self.n\n",
        "            vals = vals.view(self.n, self.shape[1]/self.n, self.shape[2], self.shape[3])\n",
        "            vals = mean(vals, axis=0, keepdim=True).view(1, self.n, 1, 1)\n",
        "        vals = vals.expand(*target_shape)\n",
        "        return torch.cat([x, vals], 1)\n",
        "\n",
        "\n",
        "####################\n",
        "# Useful blocks\n",
        "####################\n",
        "\n",
        "class SelfAttentionBlock(nn.Module):\n",
        "    \"\"\" \n",
        "        Implementation of Self attention Block according to paper \n",
        "        'Self-Attention Generative Adversarial Networks' (https://arxiv.org/abs/1805.08318)\n",
        "        Flexible Self Attention (FSA) layer according to paper\n",
        "        Efficient Super Resolution For Large-Scale Images Using Attentional GAN (https://arxiv.org/pdf/1812.04821.pdf)\n",
        "          The FSA layer borrows the self attention layer from SAGAN, \n",
        "          and wraps it with a max-pooling layer to reduce the size \n",
        "          of the feature maps and enable large-size images to fit in memory.\n",
        "        Used in Generator and Discriminator Networks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, max_pool=False, poolsize = 4, spectral_norm=False, ret_attention=False): #in_dim = in_feature_maps\n",
        "        super(SelfAttentionBlock,self).__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.max_pool = max_pool\n",
        "        self.poolsize = poolsize\n",
        "        self.ret_attention = ret_attention\n",
        "        \n",
        "        if self.max_pool:\n",
        "            self.pooled = nn.MaxPool2d(kernel_size=self.poolsize, stride=self.poolsize) #kernel_size=4, stride=4\n",
        "            # Note: can test using strided convolutions instead of MaxPool2d! :\n",
        "            #upsample_block_num = int(math.log(scale_factor, 2))\n",
        "            #self.pooled = nn.Conv2d .... strided conv\n",
        "            # upsample_o = [UpconvBlock(in_channels=in_dim, out_channels=in_dim, upscale_factor=2, mode='bilinear', act_type='leakyrelu') for _ in range(upsample_block_num)]\n",
        "            ## upsample_o.append(nn.Conv2d(nf, in_nc, kernel_size=9, stride=1, padding=4))\n",
        "            ## self.upsample_o = nn.Sequential(*upsample_o)\n",
        "\n",
        "            # self.upsample_o = B.Upsample(scale_factor=self.poolsize, mode='bilinear', align_corners=False) \n",
        "            \n",
        "        self.conv_f = add_spectral_norm(\n",
        "            nn.Conv1d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1, padding = 0), \n",
        "            use_spectral_norm=spectral_norm) #query_conv \n",
        "        self.conv_g = add_spectral_norm(\n",
        "            nn.Conv1d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1, padding = 0), \n",
        "            use_spectral_norm=spectral_norm) #key_conv \n",
        "        self.conv_h = add_spectral_norm(\n",
        "            nn.Conv1d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1, padding = 0), \n",
        "            use_spectral_norm=spectral_norm) #value_conv \n",
        "\n",
        "        self.gamma = nn.Parameter(torch.zeros(1)) # Trainable interpolation parameter\n",
        "        self.softmax  = nn.Softmax(dim = -1)\n",
        "        \n",
        "    def forward(self,input):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                input : input feature maps( B X C X W X H)\n",
        "            returns :\n",
        "                out : self attention value + input feature \n",
        "                attention: B X N X N (N is Width*Height)\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.max_pool: #Downscale with Max Pool\n",
        "            x = self.pooled(input)\n",
        "        else:\n",
        "            x = input\n",
        "            \n",
        "        batch_size, C, width, height = x.size()\n",
        "        \n",
        "        N = width * height\n",
        "        x = x.view(batch_size, -1, N)\n",
        "        f = self.conv_f(x) #proj_query  # B X CX(N)\n",
        "        g = self.conv_g(x) #proj_key    # B X C x (*W*H)\n",
        "        h = self.conv_h(x) #proj_value  # B X C X N\n",
        "\n",
        "        s = torch.bmm(f.permute(0, 2, 1), g) # energy, transpose check\n",
        "        # get probabilities\n",
        "        attention = self.softmax(s) #beta #attention # BX (N) X (N) \n",
        "        \n",
        "        out = torch.bmm(h, attention.permute(0,2,1))\n",
        "        out = out.view(batch_size, C, width, height) \n",
        "        \n",
        "        if self.max_pool: #Upscale to original size\n",
        "            # out = self.upsample_o(out)\n",
        "            out = Upsample(size=(input.shape[2],input.shape[3]), mode='bicubic', align_corners=False)(out) #bicubic (PyTorch > 1.0) | bilinear others.\n",
        "        \n",
        "        out = self.gamma*out + input #Add original input\n",
        "        \n",
        "        if self.ret_attention:\n",
        "            return out, attention\n",
        "        else:\n",
        "            return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVGp0I1Ind4T",
        "cellView": "form"
      },
      "source": [
        "#@title spectral_norm.py\n",
        "\"\"\"\n",
        "spectral_norm.py (12-2-20)\n",
        "https://github.com/victorca25/BasicSR/blob/master/codes/models/modules/spectral_norm.py\n",
        "\"\"\"\n",
        "'''\n",
        "Copy from pytorch github repo\n",
        "Spectral Normalization from https://arxiv.org/abs/1802.05957\n",
        "'''\n",
        "import torch\n",
        "from torch.nn.functional import normalize\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "class SpectralNorm(object):\n",
        "    def __init__(self, name='weight', n_power_iterations=1, dim=0, eps=1e-12):\n",
        "        self.name = name\n",
        "        self.dim = dim\n",
        "        if n_power_iterations <= 0:\n",
        "            raise ValueError('Expected n_power_iterations to be positive, but '\n",
        "                             'got n_power_iterations={}'.format(n_power_iterations))\n",
        "        self.n_power_iterations = n_power_iterations\n",
        "        self.eps = eps\n",
        "\n",
        "    def compute_weight(self, module):\n",
        "        weight = getattr(module, self.name + '_orig')\n",
        "        u = getattr(module, self.name + '_u')\n",
        "        weight_mat = weight\n",
        "        if self.dim != 0:\n",
        "            # permute dim to front\n",
        "            weight_mat = weight_mat.permute(self.dim,\n",
        "                                            *[d for d in range(weight_mat.dim()) if d != self.dim])\n",
        "        height = weight_mat.size(0)\n",
        "        weight_mat = weight_mat.reshape(height, -1)\n",
        "        with torch.no_grad():\n",
        "            for _ in range(self.n_power_iterations):\n",
        "                # Spectral norm of weight equals to `u^T W v`, where `u` and `v`\n",
        "                # are the first left and right singular vectors.\n",
        "                # This power iteration produces approximations of `u` and `v`.\n",
        "                v = normalize(torch.matmul(weight_mat.t(), u), dim=0, eps=self.eps)\n",
        "                u = normalize(torch.matmul(weight_mat, v), dim=0, eps=self.eps)\n",
        "\n",
        "        sigma = torch.dot(u, torch.matmul(weight_mat, v))\n",
        "        weight = weight / sigma\n",
        "        return weight, u\n",
        "\n",
        "    def remove(self, module):\n",
        "        weight = getattr(module, self.name)\n",
        "        delattr(module, self.name)\n",
        "        delattr(module, self.name + '_u')\n",
        "        delattr(module, self.name + '_orig')\n",
        "        module.register_parameter(self.name, torch.nn.Parameter(weight))\n",
        "\n",
        "    def __call__(self, module, inputs):\n",
        "        if module.training:\n",
        "            weight, u = self.compute_weight(module)\n",
        "            setattr(module, self.name, weight)\n",
        "            setattr(module, self.name + '_u', u)\n",
        "        else:\n",
        "            r_g = getattr(module, self.name + '_orig').requires_grad\n",
        "            getattr(module, self.name).detach_().requires_grad_(r_g)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply(module, name, n_power_iterations, dim, eps):\n",
        "        fn = SpectralNorm(name, n_power_iterations, dim, eps)\n",
        "        weight = module._parameters[name]\n",
        "        height = weight.size(dim)\n",
        "\n",
        "        u = normalize(weight.new_empty(height).normal_(0, 1), dim=0, eps=fn.eps)\n",
        "        delattr(module, fn.name)\n",
        "        module.register_parameter(fn.name + \"_orig\", weight)\n",
        "        # We still need to assign weight back as fn.name because all sorts of\n",
        "        # things may assume that it exists, e.g., when initializing weights.\n",
        "        # However, we can't directly assign as it could be an nn.Parameter and\n",
        "        # gets added as a parameter. Instead, we register weight.data as a\n",
        "        # buffer, which will cause weight to be included in the state dict\n",
        "        # and also supports nn.init due to shared storage.\n",
        "        module.register_buffer(fn.name, weight.data)\n",
        "        module.register_buffer(fn.name + \"_u\", u)\n",
        "\n",
        "        module.register_forward_pre_hook(fn)\n",
        "        return fn\n",
        "\n",
        "\n",
        "def spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None):\n",
        "    r\"\"\"Applies spectral normalization to a parameter in the given module.\n",
        "\n",
        "    .. math::\n",
        "         \\mathbf{W} &= \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})} \\\\\n",
        "         \\sigma(\\mathbf{W}) &= \\max_{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{\\|\\mathbf{W} \\mathbf{h}\\|_2}{\\|\\mathbf{h}\\|_2}\n",
        "\n",
        "    Spectral normalization stabilizes the training of discriminators (critics)\n",
        "    in Generaive Adversarial Networks (GANs) by rescaling the weight tensor\n",
        "    with spectral norm :math:`\\sigma` of the weight matrix calculated using\n",
        "    power iteration method. If the dimension of the weight tensor is greater\n",
        "    than 2, it is reshaped to 2D in power iteration method to get spectral\n",
        "    norm. This is implemented via a hook that calculates spectral norm and\n",
        "    rescales weight before every :meth:`~Module.forward` call.\n",
        "\n",
        "    See `Spectral Normalization for Generative Adversarial Networks`_ .\n",
        "\n",
        "    .. _`Spectral Normalization for Generative Adversarial Networks`: https://arxiv.org/abs/1802.05957\n",
        "\n",
        "    Args:\n",
        "        module (nn.Module): containing module\n",
        "        name (str, optional): name of weight parameter\n",
        "        n_power_iterations (int, optional): number of power iterations to\n",
        "            calculate spectal norm\n",
        "        eps (float, optional): epsilon for numerical stability in\n",
        "            calculating norms\n",
        "        dim (int, optional): dimension corresponding to number of outputs,\n",
        "            the default is 0, except for modules that are instances of\n",
        "            ConvTranspose1/2/3d, when it is 1\n",
        "\n",
        "    Returns:\n",
        "        The original module with the spectal norm hook\n",
        "\n",
        "    Example::\n",
        "\n",
        "        >>> m = spectral_norm(nn.Linear(20, 40))\n",
        "        Linear (20 -> 40)\n",
        "        >>> m.weight_u.size()\n",
        "        torch.Size([20])\n",
        "\n",
        "    \"\"\"\n",
        "    if dim is None:\n",
        "        if isinstance(\n",
        "                module,\n",
        "            (torch.nn.ConvTranspose1d, torch.nn.ConvTranspose2d, torch.nn.ConvTranspose3d)):\n",
        "            dim = 1\n",
        "        else:\n",
        "            dim = 0\n",
        "    SpectralNorm.apply(module, name, n_power_iterations, dim, eps)\n",
        "    return module\n",
        "\n",
        "\n",
        "def remove_spectral_norm(module, name='weight'):\n",
        "    r\"\"\"Removes the spectral normalization reparameterization from a module.\n",
        "\n",
        "    Args:\n",
        "        module (nn.Module): containing module\n",
        "        name (str, optional): name of weight parameter\n",
        "\n",
        "    Example:\n",
        "        >>> m = spectral_norm(nn.Linear(40, 10))\n",
        "        >>> remove_spectral_norm(m)\n",
        "    \"\"\"\n",
        "    for k, hook in module._forward_pre_hooks.items():\n",
        "        if isinstance(hook, SpectralNorm) and hook.name == name:\n",
        "            hook.remove(module)\n",
        "            del module._forward_pre_hooks[k]\n",
        "            return module\n",
        "\n",
        "    raise ValueError(\"spectral_norm of '{}' not found in {}\".format(name, module))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef_-I2mZx9Ru"
      },
      "source": [
        "Inside ``CustomTrainClass`` it is possible to configure loss functions and weights. Configure logging path inside ``CustomTrainClass.py``. \n",
        "\n",
        "Warning: Don't use AMP with StyleLoss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKp21IihhGkL"
      },
      "source": [
        "**Warning**: Certain combinations of discriminator and generator can result in crappy validation images. Test for a short while and make sure it isn't a solid color."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7P_Ojbv6NC",
        "cellView": "form"
      },
      "source": [
        "#@title ESRGAN_arch.py\n",
        "\"\"\"\n",
        "RRDBNet_arch.py (12-2-20)\n",
        "https://github.com/victorca25/BasicSR/blob/master/codes/models/modules/architectures/RRDBNet_arch.py\n",
        "\"\"\"\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torchvision\n",
        "#from . import block as B\n",
        "import functools\n",
        "#from . import spectral_norm as SN\n",
        "\n",
        "\n",
        "####################\n",
        "# RRDBNet Generator (original architecture)\n",
        "####################\n",
        "\n",
        "class RRDBNet(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, nr=3, gc=32, upscale=4, norm_type=None, \\\n",
        "            act_type='leakyrelu', mode='CNA', upsample_mode='upconv', convtype='Conv2D', \\\n",
        "            finalact=None, gaussian_noise=False, plus=False):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        n_upscale = int(math.log(upscale, 2))\n",
        "        if upscale == 3:\n",
        "            n_upscale = 1\n",
        "\n",
        "        fea_conv = conv_block(in_nc, nf, kernel_size=3, norm_type=None, act_type=None, convtype=convtype)\n",
        "        rb_blocks = [RRDB(nf, nr, kernel_size=3, gc=32, stride=1, bias=1, pad_type='zero', \\\n",
        "            norm_type=norm_type, act_type=act_type, mode='CNA', convtype=convtype, \\\n",
        "            gaussian_noise=gaussian_noise, plus=plus) for _ in range(nb)]\n",
        "        LR_conv = conv_block(nf, nf, kernel_size=3, norm_type=norm_type, act_type=None, mode=mode, convtype=convtype)\n",
        "\n",
        "        if upsample_mode == 'upconv':\n",
        "            upsample_block = upconv_block\n",
        "        elif upsample_mode == 'pixelshuffle':\n",
        "            upsample_block = pixelshuffle_block\n",
        "        else:\n",
        "            raise NotImplementedError('upsample mode [{:s}] is not found'.format(upsample_mode))\n",
        "        if upscale == 3:\n",
        "            upsampler = upsample_block(nf, nf, 3, act_type=act_type, convtype=convtype)\n",
        "        else:\n",
        "            upsampler = [upsample_block(nf, nf, act_type=act_type, convtype=convtype) for _ in range(n_upscale)]\n",
        "        HR_conv0 = conv_block(nf, nf, kernel_size=3, norm_type=None, act_type=act_type, convtype=convtype)\n",
        "        HR_conv1 = conv_block(nf, out_nc, kernel_size=3, norm_type=None, act_type=None, convtype=convtype)\n",
        "\n",
        "        # Note: this option adds new parameters to the architecture, another option is to use \"outm\" in the forward\n",
        "        outact = act(finalact) if finalact else None\n",
        "        \n",
        "        self.model = sequential(fea_conv, ShortcutBlock(sequential(*rb_blocks, LR_conv)),\\\n",
        "            *upsampler, HR_conv0, HR_conv1, outact)\n",
        "\n",
        "    def forward(self, x, outm=None):\n",
        "        x = self.model(x)\n",
        "        \n",
        "        if outm=='scaltanh': # limit output range to [-1,1] range with tanh and rescale to [0,1] Idea from: https://github.com/goldhuang/SRGAN-PyTorch/blob/master/model.py\n",
        "            return(torch.tanh(x) + 1.0) / 2.0\n",
        "        elif outm=='tanh': # limit output to [-1,1] range\n",
        "            return torch.tanh(x)\n",
        "        elif outm=='sigmoid': # limit output to [0,1] range\n",
        "            return torch.sigmoid(x)\n",
        "        elif outm=='clamp':\n",
        "            return torch.clamp(x, min=0.0, max=1.0)\n",
        "        else: #Default, no cap for the output\n",
        "            return x\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    '''\n",
        "    Residual in Residual Dense Block\n",
        "    (ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, nf, nr=3, kernel_size=3, gc=32, stride=1, bias=1, pad_type='zero', \\\n",
        "            norm_type=None, act_type='leakyrelu', mode='CNA', convtype='Conv2D', \\\n",
        "            spectral_norm=False, gaussian_noise=False, plus=False):\n",
        "        super(RRDB, self).__init__()\n",
        "        # This is for backwards compatibility with existing models\n",
        "        if nr == 3:\n",
        "            self.RDB1 = ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type, \\\n",
        "                    norm_type, act_type, mode, convtype, spectral_norm=spectral_norm, \\\n",
        "                    gaussian_noise=gaussian_noise, plus=plus)\n",
        "            self.RDB2 = ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type, \\\n",
        "                    norm_type, act_type, mode, convtype, spectral_norm=spectral_norm, \\\n",
        "                    gaussian_noise=gaussian_noise, plus=plus)\n",
        "            self.RDB3 = ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type, \\\n",
        "                    norm_type, act_type, mode, convtype, spectral_norm=spectral_norm, \\\n",
        "                    gaussian_noise=gaussian_noise, plus=plus)\n",
        "        else:\n",
        "            RDB_list = [ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type,\n",
        "                                              norm_type, act_type, mode, convtype, spectral_norm=spectral_norm,\n",
        "                                              gaussian_noise=gaussian_noise, plus=plus) for _ in range(nr)]\n",
        "            self.RDBs = nn.Sequential(*RDB_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if hasattr(self, 'RDB1'):\n",
        "            out = self.RDB1(x)\n",
        "            out = self.RDB2(out)\n",
        "            out = self.RDB3(out)\n",
        "        else:\n",
        "            out = self.RDBs(x)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "class ResidualDenseBlock_5C(nn.Module):\n",
        "    '''\n",
        "    Residual Dense Block\n",
        "    style: 5 convs\n",
        "    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)\n",
        "    Modified options that can be used:\n",
        "        - \"Partial Convolution based Padding\" arXiv:1811.11718\n",
        "        - \"Spectral normalization\" arXiv:1802.05957\n",
        "        - \"ICASSP 2020 - ESRGAN+ : Further Improving ESRGAN\" N. C. \n",
        "            {Rakotonirina} and A. {Rasoanaivo}\n",
        "    \n",
        "    Args:\n",
        "        nf (int): Channel number of intermediate features (num_feat).\n",
        "        gc (int): Channels for each growth (num_grow_ch: growth channel, \n",
        "            i.e. intermediate channels).\n",
        "        convtype (str): the type of convolution to use. Default: 'Conv2D'\n",
        "        gaussian_noise (bool): enable the ESRGAN+ gaussian noise (no new \n",
        "            trainable parameters)\n",
        "        plus (bool): enable the additional residual paths from ESRGAN+ \n",
        "            (adds trainable parameters)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, nf=64, kernel_size=3, gc=32, stride=1, bias=1, pad_type='zero', \\\n",
        "            norm_type=None, act_type='leakyrelu', mode='CNA', convtype='Conv2D', \\\n",
        "            spectral_norm=False, gaussian_noise=False, plus=False):\n",
        "        super(ResidualDenseBlock_5C, self).__init__()\n",
        "        \n",
        "        ## +\n",
        "        self.noise = GaussianNoise() if gaussian_noise else None\n",
        "        self.conv1x1 = conv1x1(nf, gc) if plus else None\n",
        "        ## +\n",
        "\n",
        "        self.conv1 = conv_block(nf, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        self.conv2 = conv_block(nf+gc, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        self.conv3 = conv_block(nf+2*gc, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        self.conv4 = conv_block(nf+3*gc, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        if mode == 'CNA':\n",
        "            last_act = None\n",
        "        else:\n",
        "            last_act = act_type\n",
        "        self.conv5 = conv_block(nf+4*gc, nf, 3, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=last_act, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.conv2(torch.cat((x, x1), 1))\n",
        "        if self.conv1x1:\n",
        "            x2 = x2 + self.conv1x1(x) #+\n",
        "        x3 = self.conv3(torch.cat((x, x1, x2), 1))\n",
        "        x4 = self.conv4(torch.cat((x, x1, x2, x3), 1))\n",
        "        if self.conv1x1:\n",
        "            x4 = x4 + x2 #+\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        if self.noise:\n",
        "            return self.noise(x5.mul(0.2) + x)\n",
        "        else:\n",
        "            return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "####################\n",
        "# RRDBNet Generator (modified/\"new\" architecture)\n",
        "####################\n",
        "\n",
        "\n",
        "class MRRDBNet(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, gc=32):\n",
        "        super(MRRDBNet, self).__init__()\n",
        "        RRDB_block_f = functools.partial(RRDBM, nf=nf, gc=gc)\n",
        "\n",
        "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
        "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        #### upsampling\n",
        "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fea = self.conv_first(x)\n",
        "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
        "        fea = fea + trunk\n",
        "\n",
        "        fea = self.lrelu(self.upconv1(torch.nn.functional.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        fea = self.lrelu(self.upconv2(torch.nn.functional.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResidualDenseBlock_5CM(nn.Module):\n",
        "    '''\n",
        "    Residual Dense Block\n",
        "    '''\n",
        "    def __init__(self, nf=64, gc=32, bias=True):\n",
        "        super(ResidualDenseBlock_5CM, self).__init__()\n",
        "        # gc: growth channel, i.e. intermediate channels\n",
        "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        # initialization\n",
        "        default_init_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], scale=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "class RRDBM(nn.Module):\n",
        "    '''Residual in Residual Dense Block'''\n",
        "\n",
        "    def __init__(self, nf, gc=32):\n",
        "        super(RRDBM, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock_5CM(nf, gc)\n",
        "        self.RDB2 = ResidualDenseBlock_5CM(nf, gc)\n",
        "        self.RDB3 = ResidualDenseBlock_5CM(nf, gc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "        return out * 0.2 + x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz--7Uq8FtQe"
      },
      "source": [
        "# Getting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zUaRC8dwC8I",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "%cd /content/\n",
        "#!wget https://b2.fromtheexchange.space/file/space-fromtheexchange-b2/colab/model-conversion/v1/RRDB_ESRGAN_x4.pth\n",
        "#!gdown --id 19qzrIGWUW3eu5troIjHzhCIbTZONSRjX\n",
        "\n",
        "#%cd /content/\n",
        "!wget https://f002.backblazeb2.com/file/ESRGAN/_RELEASE/4x_cat_patch_325000_G.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZc7QSEN2uoR"
      },
      "source": [
        "# Converting\n",
        "Output will be in ``/content/output.onnx``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en-4jluU-0uH",
        "cellView": "form"
      },
      "source": [
        "%cd /content/\n",
        "# setting needed params, norm_type will be forced to None\n",
        "model = RRDBNet(in_nc=3, out_nc=3, nf=64, nb=23, gc=32, upscale=4, norm_type='null',\n",
        "            act_type='leakyrelu', mode='CNA', upsample_mode='upconv', convtype='Conv2D',\n",
        "            finalact=None, gaussian_noise=True, plus=False, \n",
        "            nr=3)\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.onnx\n",
        "import torchvision\n",
        "import torch\n",
        "\n",
        "dummy_input = Variable(torch.randn(1, 3, 64, 64)) # don't set it too high, will run out of RAM\n",
        "model_path = '/content/4x_cat_patch_325000_G.pth' #@param\n",
        "state_dict = torch.load(model_path)\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.eval()\n",
        "\n",
        "#torch.onnx.export(model, dummy_input, \"output.onnx\")\n",
        "torch.onnx.export(model, dummy_input, \"output.onnx\", opset_version=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAeg3lAQQObZ"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-HtsK1uPVpN"
      },
      "source": [
        "# torch.jit.save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "neaKzlIFPYF7"
      },
      "source": [
        "#@title torch.jit.save\n",
        "model_path = '/content/4x_cat_patch_325000_G.pth' #@param\n",
        "state_dict = torch.load(model_path)\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.eval()\n",
        "\n",
        "traced_model = torch.jit.trace(model, torch.randn(1,3,60,60))\n",
        "torch.jit.save(traced_model, 'traces.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgyHh45fQKuF"
      },
      "source": [
        "# torch.jit.script\n",
        "\n",
        "Using ``torch.jit.script`` to generate the picture. ``torch.jit.script`` does not like certain parts of the code, so I just removed them to make ``torch.jit.script`` usable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qLflMaAJSdNZ"
      },
      "source": [
        "#@title block.py (removing if self.training and self.sigma != 0:)\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from models.modules.architectures.convolutions.partialconv2d import PartialConv2d #TODO\n",
        "#from models.modules.architectures.convolutions.deformconv2d import DeformConv2d\n",
        "#from models.networks import weights_init_normal, weights_init_xavier, weights_init_kaiming, weights_init_orthogonal\n",
        "\n",
        "\n",
        "####################\n",
        "# Basic blocks\n",
        "####################\n",
        "\n",
        "# Swish activation funtion\n",
        "def swish_func(x, beta=1.0):\n",
        "    \"\"\"\n",
        "    \"Swish: a Self-Gated Activation Function\"\n",
        "    Searching for Activation Functions (https://arxiv.org/abs/1710.05941)\n",
        "    \n",
        "    If beta=1 applies the Sigmoid Linear Unit (SiLU) function element-wise\n",
        "    If beta=0, Swish becomes the scaled linear function (identity \n",
        "      activation) f(x) = x/2\n",
        "    As beta -> âˆž, the sigmoid component converges to approach a 0-1 function\n",
        "      (unit step), and multiplying that by x gives us f(x)=2max(0,x), which \n",
        "      is the ReLU multiplied by a constant factor of 2, so Swish becomes like \n",
        "      the ReLU function.\n",
        "    \n",
        "    Including beta, Swish can be loosely viewed as a smooth function that \n",
        "      nonlinearly interpolate between identity (linear) and ReLU function.\n",
        "      The degree of interpolation can be controlled by the model if beta is \n",
        "      set as a trainable parameter.\n",
        "    \n",
        "    Alt: 1.78718727865 * (x * sigmoid(x) - 0.20662096414)\n",
        "    \"\"\"\n",
        "    \n",
        "    # In-place implementation, may consume less GPU memory: \n",
        "    \"\"\" \n",
        "    result = x.clone()\n",
        "    torch.sigmoid_(beta*x)\n",
        "    x *= result\n",
        "    return x\n",
        "    #\"\"\"\n",
        "    \n",
        "    # Normal out-of-place implementation:\n",
        "    #\"\"\"\n",
        "    return x * torch.sigmoid(beta * x)\n",
        "    #\"\"\"\n",
        "    \n",
        "# Swish module\n",
        "class Swish(nn.Module):\n",
        "    \n",
        "    __constants__ = ['beta', 'slope', 'inplace']\n",
        "    \n",
        "    def __init__(self, beta=1.0, slope=1.67653251702, inplace=False):\n",
        "        \"\"\"\n",
        "        Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "        \"\"\"\n",
        "        super(Swish).__init__()\n",
        "        self.inplace = inplace\n",
        "        # self.beta = beta # user-defined beta parameter, non-trainable\n",
        "        # self.beta = beta * torch.nn.Parameter(torch.ones(1)) # learnable beta parameter, create a tensor out of beta\n",
        "        self.beta = torch.nn.Parameter(torch.tensor(beta)) # learnable beta parameter, create a tensor out of beta\n",
        "        self.beta.requiresGrad = True # set requiresGrad to true to make it trainable\n",
        "\n",
        "        self.slope = slope / 2 # user-defined \"slope\", non-trainable\n",
        "        # self.slope = slope * torch.nn.Parameter(torch.ones(1)) # learnable slope parameter, create a tensor out of slope\n",
        "        # self.slope = torch.nn.Parameter(torch.tensor(slope)) # learnable slope parameter, create a tensor out of slope\n",
        "        # self.slope.requiresGrad = True # set requiresGrad to true to true to make it trainable\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        # Disabled, using inplace causes:\n",
        "        # \"RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation\"\n",
        "        if self.inplace:\n",
        "            input.mul_(torch.sigmoid(self.beta*input))\n",
        "            return 2 * self.slope * input\n",
        "        else:\n",
        "            return 2 * self.slope * swish_func(input, self.beta)\n",
        "        \"\"\"\n",
        "        return 2 * self.slope * swish_func(input, self.beta)\n",
        "\n",
        "\n",
        "def act(act_type, inplace=True, neg_slope=0.2, n_prelu=1, beta=1.0):\n",
        "    # helper selecting activation\n",
        "    # neg_slope: for leakyrelu and init of prelu\n",
        "    # n_prelu: for p_relu num_parameters\n",
        "    # beta: for swish\n",
        "    act_type = act_type.lower()\n",
        "    if act_type == 'relu':\n",
        "        layer = nn.ReLU(inplace)\n",
        "    elif act_type == 'leakyrelu' or act_type == 'lrelu':\n",
        "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
        "    elif act_type == 'prelu':\n",
        "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
        "    elif act_type == 'Tanh' or act_type == 'tanh':  # [-1, 1] range output\n",
        "        layer = nn.Tanh()\n",
        "    elif act_type == 'sigmoid':  # [0, 1] range output\n",
        "        layer = nn.Sigmoid()\n",
        "    elif act_type == 'swish':\n",
        "        layer = Swish(beta=beta, inplace=inplace)\n",
        "    else:\n",
        "        raise NotImplementedError('activation layer [{:s}] is not found'.format(act_type))\n",
        "    return layer\n",
        "\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self, *kwargs):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x, *kwargs):\n",
        "        return x\n",
        "\n",
        "\n",
        "def norm(norm_type, nc):\n",
        "    \"\"\"Return a normalization layer\n",
        "    Parameters:\n",
        "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
        "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
        "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
        "    \"\"\"\n",
        "    norm_type = norm_type.lower()\n",
        "    if norm_type == 'batch':\n",
        "        layer = nn.BatchNorm2d(nc, affine=True)\n",
        "        # norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
        "    elif norm_type == 'instance':\n",
        "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
        "        # norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
        "    # elif norm_type == 'layer':\n",
        "    #     return lambda num_features: nn.GroupNorm(1, num_features)\n",
        "    elif norm_type == 'none':\n",
        "        def norm_layer(x): return Identity()\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [{:s}] is not found'.format(norm_type))\n",
        "    return layer\n",
        "\n",
        "\n",
        "def add_spectral_norm(module, use_spectral_norm=False):\n",
        "    \"\"\" Add spectral norm to any module passed if use_spectral_norm = True,\n",
        "    else, returns the original module without change\n",
        "    \"\"\"\n",
        "    if use_spectral_norm:\n",
        "        return nn.utils.spectral_norm(module)\n",
        "    return module\n",
        "\n",
        "\n",
        "def pad(pad_type, padding):\n",
        "    \"\"\"\n",
        "    helper selecting padding layer\n",
        "    if padding is 'zero', can be done with conv layers\n",
        "    \"\"\"\n",
        "    pad_type = pad_type.lower()\n",
        "    if padding == 0:\n",
        "        return None\n",
        "    if pad_type == 'reflect':\n",
        "        layer = nn.ReflectionPad2d(padding)\n",
        "    elif pad_type == 'replicate':\n",
        "        layer = nn.ReplicationPad2d(padding)\n",
        "    elif pad_type == 'zero':\n",
        "        layer = nn.ZeroPad2d(padding)\n",
        "    else:\n",
        "        raise NotImplementedError('padding layer [{:s}] is not implemented'.format(pad_type))\n",
        "    return layer\n",
        "\n",
        "\n",
        "def get_valid_padding(kernel_size, dilation):\n",
        "    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
        "    padding = (kernel_size - 1) // 2\n",
        "    return padding\n",
        "\n",
        "\n",
        "class ConcatBlock(nn.Module):\n",
        "    # Concat the output of a submodule to its input\n",
        "    def __init__(self, submodule):\n",
        "        super(ConcatBlock, self).__init__()\n",
        "        self.sub = submodule\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.cat((x, self.sub(x)), dim=1)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Identity .. \\n|' + self.sub.__repr__().replace('\\n', '\\n|')\n",
        "\n",
        "\n",
        "class ShortcutBlock(nn.Module):\n",
        "    # Elementwise sum the output of a submodule to its input\n",
        "    def __init__(self, submodule):\n",
        "        super(ShortcutBlock, self).__init__()\n",
        "        self.sub = submodule\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x + self.sub(x)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Identity + \\n|' + self.sub.__repr__().replace('\\n', '\\n|')\n",
        "\n",
        "\n",
        "def sequential(*args):\n",
        "    # Flatten Sequential. It unwraps nn.Sequential.\n",
        "    if len(args) == 1:\n",
        "        if isinstance(args[0], OrderedDict):\n",
        "            raise NotImplementedError('sequential does not support OrderedDict input.')\n",
        "        return args[0]  # No sequential is needed.\n",
        "    modules = []\n",
        "    for module in args:\n",
        "        if isinstance(module, nn.Sequential):\n",
        "            for submodule in module.children():\n",
        "                modules.append(submodule)\n",
        "        elif isinstance(module, nn.Module):\n",
        "            modules.append(module)\n",
        "    return nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "def conv_block(in_nc, out_nc, kernel_size, stride=1, dilation=1, groups=1, bias=True, \\\n",
        "               pad_type='zero', norm_type=None, act_type='relu', mode='CNA', convtype='Conv2D', \\\n",
        "               spectral_norm=False):\n",
        "    \"\"\"\n",
        "    Conv layer with padding, normalization, activation\n",
        "    mode: CNA --> Conv -> Norm -> Act\n",
        "        NAC --> Norm -> Act --> Conv (Identity Mappings in Deep Residual Networks, ECCV16)\n",
        "    \"\"\"\n",
        "    assert mode in ['CNA', 'NAC', 'CNAC'], 'Wrong conv mode [{:s}]'.format(mode)\n",
        "    padding = get_valid_padding(kernel_size, dilation)\n",
        "    p = pad(pad_type, padding) if pad_type and pad_type != 'zero' else None\n",
        "    padding = padding if pad_type == 'zero' else 0\n",
        "    \n",
        "    if convtype=='PartialConv2D':\n",
        "        c = PartialConv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "               dilation=dilation, bias=bias, groups=groups)\n",
        "    elif convtype=='DeformConv2D':\n",
        "        c = DeformConv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "               dilation=dilation, bias=bias, groups=groups)\n",
        "    elif convtype=='Conv3D':\n",
        "        c = nn.Conv3d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "                dilation=dilation, bias=bias, groups=groups)\n",
        "    else: #default case is standard 'Conv2D':\n",
        "        c = nn.Conv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding, \\\n",
        "                dilation=dilation, bias=bias, groups=groups) #normal conv2d\n",
        "            \n",
        "    if spectral_norm:\n",
        "        c = nn.utils.spectral_norm(c)\n",
        "    \n",
        "    a = act(act_type) if act_type else None\n",
        "    if 'CNA' in mode:\n",
        "        #n = norm(norm_type, out_nc) if norm_type else None\n",
        "        n = None\n",
        "        return sequential(p, c, n, a)\n",
        "    elif mode == 'NAC':\n",
        "        if norm_type is None and act_type is not None:\n",
        "            a = act(act_type, inplace=False)\n",
        "            # Important!\n",
        "            # input----ReLU(inplace)----Conv--+----output\n",
        "            #        |________________________|\n",
        "            # inplace ReLU will modify the input, therefore wrong output\n",
        "        n = norm(norm_type, in_nc) if norm_type else None\n",
        "        return sequential(n, a, p, c)\n",
        "\n",
        "\n",
        "def make_layer(basic_block, num_basic_block, **kwarg):\n",
        "    \"\"\"Make layers by stacking the same blocks.\n",
        "    Args:\n",
        "        basic_block (nn.module): nn.module class for basic block. (block)\n",
        "        num_basic_block (int): number of blocks. (n_layers)\n",
        "    Returns:\n",
        "        nn.Sequential: Stacked blocks in nn.Sequential.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    for _ in range(num_basic_block):\n",
        "        layers.append(basic_block(**kwarg))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class Mean(nn.Module):\n",
        "  def __init__(self, dim: list, keepdim=False):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.keepdim = keepdim\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.mean(x, self.dim, self.keepdim)\n",
        "\n",
        "\n",
        "####################\n",
        "# initialize modules\n",
        "####################\n",
        "\n",
        "@torch.no_grad()\n",
        "def default_init_weights(module_list, init_type='kaiming', scale=1, bias_fill=0, **kwargs):\n",
        "    \"\"\"Initialize network weights.\n",
        "    Args:\n",
        "        module_list (list[nn.Module] | nn.Module): Modules to be initialized.\n",
        "        init_type (str): the type of initialization in: 'normal', 'kaiming' \n",
        "            or 'orthogonal'\n",
        "        scale (float): Scale initialized weights, especially for residual\n",
        "            blocks. Default: 1. (for 'kaiming')\n",
        "        bias_fill (float): The value to fill bias. Default: 0\n",
        "        kwargs (dict): Other arguments for initialization function:\n",
        "            mean and/or std for 'normal'.\n",
        "            a and/or mode for 'kaiming'\n",
        "            gain for 'orthogonal' and xavier\n",
        "    \"\"\"\n",
        "    \n",
        "    # TODO\n",
        "    # logger.info('Initialization method [{:s}]'.format(init_type))\n",
        "    if not isinstance(module_list, list):\n",
        "        module_list = [module_list]\n",
        "    for module in module_list:\n",
        "        for m in module.modules():\n",
        "            if init_type == 'normal':\n",
        "                weights_init_normal(m, bias_fill=bias_fill, **kwargs)\n",
        "            if init_type == 'xavier':\n",
        "                weights_init_xavier(m, scale=scale, bias_fill=bias_fill, **kwargs)    \n",
        "            elif init_type == 'kaiming':\n",
        "                weights_init_kaiming(m, scale=scale, bias_fill=bias_fill, **kwargs)\n",
        "            elif init_type == 'orthogonal':\n",
        "                weights_init_orthogonal(m, bias_fill=bias_fill)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [{:s}] not implemented'.format(init_type))\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# Upsampler\n",
        "####################\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    r\"\"\"Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\n",
        "\n",
        "    The input data is assumed to be of the form\n",
        "    `minibatch x channels x [optional depth] x [optional height] x width`.\n",
        "\n",
        "    Args:\n",
        "        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], optional):\n",
        "            output spatial sizes\n",
        "        scale_factor (float or Tuple[float] or Tuple[float, float] or Tuple[float, float, float], optional):\n",
        "            multiplier for spatial size. Has to match input size if it is a tuple.\n",
        "        mode (str, optional): the upsampling algorithm: one of ``'nearest'``,\n",
        "            ``'linear'``, ``'bilinear'``, ``'bicubic'`` and ``'trilinear'``.\n",
        "            Default: ``'nearest'``\n",
        "        align_corners (bool, optional): if ``True``, the corner pixels of the input\n",
        "            and output tensors are aligned, and thus preserving the values at\n",
        "            those pixels. This only has effect when :attr:`mode` is\n",
        "            ``'linear'``, ``'bilinear'``, or ``'trilinear'``. Default: ``False``\n",
        "    \"\"\"\n",
        "    # To prevent warning: nn.Upsample is deprecated\n",
        "    # https://discuss.pytorch.org/t/which-function-is-better-for-upsampling-upsampling-or-interpolate/21811/8\n",
        "    # From: https://pytorch.org/docs/stable/_modules/torch/nn/modules/upsampling.html#Upsample\n",
        "    # Alternative: https://discuss.pytorch.org/t/using-nn-function-interpolate-inside-nn-sequential/23588/2?u=ptrblck\n",
        "    \n",
        "    def __init__(self, size=None, scale_factor=None, mode=\"nearest\", align_corners=None):\n",
        "        super(Upsample, self).__init__()\n",
        "        if isinstance(scale_factor, tuple):\n",
        "            self.scale_factor = tuple(float(factor) for factor in scale_factor)\n",
        "        else:\n",
        "            self.scale_factor = float(scale_factor) if scale_factor else None\n",
        "        self.mode = mode\n",
        "        self.size = size\n",
        "        self.align_corners = align_corners\n",
        "        # self.interp = nn.functional.interpolate\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return nn.functional.interpolate(x, size=self.size, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
        "        # return self.interp(x, size=self.size, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
        "    \n",
        "    def extra_repr(self):\n",
        "        if self.scale_factor is not None:\n",
        "            info = 'scale_factor=' + str(self.scale_factor)\n",
        "        else:\n",
        "            info = 'size=' + str(self.size)\n",
        "        info += ', mode=' + self.mode\n",
        "        return info\n",
        "\n",
        "def pixelshuffle_block(in_nc, out_nc, upscale_factor=2, kernel_size=3, stride=1, bias=True, \\\n",
        "                        pad_type='zero', norm_type=None, act_type='relu', convtype='Conv2D'):\n",
        "    \"\"\"\n",
        "    Pixel shuffle layer\n",
        "    (Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional\n",
        "    Neural Network, CVPR17)\n",
        "    \"\"\"\n",
        "    conv = conv_block(in_nc, out_nc * (upscale_factor ** 2), kernel_size, stride, bias=bias, \\\n",
        "                        pad_type=pad_type, norm_type=None, act_type=None, convtype=convtype)\n",
        "    pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "    n = norm(norm_type, out_nc) if norm_type else None\n",
        "    a = act(act_type) if act_type else None\n",
        "    return sequential(conv, pixel_shuffle, n, a)\n",
        "\n",
        "def upconv_block(in_nc, out_nc, upscale_factor=2, kernel_size=3, stride=1, bias=True, \\\n",
        "                pad_type='zero', norm_type=None, act_type='relu', mode='nearest', convtype='Conv2D'):\n",
        "    \"\"\"\n",
        "    Upconv layer described in https://distill.pub/2016/deconv-checkerboard/\n",
        "    Example to replace deconvolutions: \n",
        "        - from: nn.ConvTranspose2d(in_nc, out_nc, kernel_size=4, stride=2, padding=1)\n",
        "        - to: upconv_block(in_nc, out_nc,kernel_size=3, stride=1, act_type=None)\n",
        "    \"\"\"\n",
        "    # upsample = nn.Upsample(scale_factor=upscale_factor, mode=mode)\n",
        "    upscale_factor = (1, upscale_factor, upscale_factor) if convtype == 'Conv3D' else upscale_factor\n",
        "    upsample = Upsample(scale_factor=upscale_factor, mode=mode) #Updated to prevent the \"nn.Upsample is deprecated\" Warning\n",
        "    conv = conv_block(in_nc, out_nc, kernel_size, stride, bias=bias, \\\n",
        "                        pad_type=pad_type, norm_type=norm_type, act_type=act_type, convtype=convtype)\n",
        "    return sequential(upsample, conv)\n",
        "\n",
        "# PPON\n",
        "def conv_layer(in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1):\n",
        "    padding = int((kernel_size - 1) / 2) * dilation\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, bias=True, dilation=dilation, groups=groups)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# ESRGANplus\n",
        "####################\n",
        "\n",
        "class GaussianNoise(nn.Module):\n",
        "    def __init__(self, sigma=0.1, is_relative_detach=False):\n",
        "        super().__init__()\n",
        "        self.sigma = sigma\n",
        "        self.is_relative_detach = is_relative_detach\n",
        "        self.noise = torch.tensor(0, dtype=torch.float).to(torch.device('cuda'))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        if self.training and self.sigma != 0:\n",
        "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
        "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
        "            x = x + sampled_noise\n",
        "        \"\"\"\n",
        "        return x \n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "# TODO: Not used:\n",
        "# https://github.com/github-pengge/PyTorch-progressive_growing_of_gans/blob/master/models/base_model.py\n",
        "class minibatch_std_concat_layer(nn.Module):\n",
        "    def __init__(self, averaging='all'):\n",
        "        super(minibatch_std_concat_layer, self).__init__()\n",
        "        self.averaging = averaging.lower()\n",
        "        if 'group' in self.averaging:\n",
        "            self.n = int(self.averaging[5:])\n",
        "        else:\n",
        "            assert self.averaging in ['all', 'flat', 'spatial', 'none', 'gpool'], 'Invalid averaging mode'%self.averaging\n",
        "        self.adjusted_std = lambda x, **kwargs: torch.sqrt(torch.mean((x - torch.mean(x, **kwargs)) ** 2, **kwargs) + 1e-8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = list(x.size())\n",
        "        target_shape = copy.deepcopy(shape)\n",
        "        vals = self.adjusted_std(x, dim=0, keepdim=True)\n",
        "        if self.averaging == 'all':\n",
        "            target_shape[1] = 1\n",
        "            vals = torch.mean(vals, dim=1, keepdim=True)\n",
        "        elif self.averaging == 'spatial':\n",
        "            if len(shape) == 4:\n",
        "                vals = mean(vals, axis=[2,3], keepdim=True)             # torch.mean(torch.mean(vals, 2, keepdim=True), 3, keepdim=True)\n",
        "        elif self.averaging == 'none':\n",
        "            target_shape = [target_shape[0]] + [s for s in target_shape[1:]]\n",
        "        elif self.averaging == 'gpool':\n",
        "            if len(shape) == 4:\n",
        "                vals = mean(x, [0,2,3], keepdim=True)                   # torch.mean(torch.mean(torch.mean(x, 2, keepdim=True), 3, keepdim=True), 0, keepdim=True)\n",
        "        elif self.averaging == 'flat':\n",
        "            target_shape[1] = 1\n",
        "            vals = torch.FloatTensor([self.adjusted_std(x)])\n",
        "        else:                                                           # self.averaging == 'group'\n",
        "            target_shape[1] = self.n\n",
        "            vals = vals.view(self.n, self.shape[1]/self.n, self.shape[2], self.shape[3])\n",
        "            vals = mean(vals, axis=0, keepdim=True).view(1, self.n, 1, 1)\n",
        "        vals = vals.expand(*target_shape)\n",
        "        return torch.cat([x, vals], 1)\n",
        "\n",
        "\n",
        "####################\n",
        "# Useful blocks\n",
        "####################\n",
        "\n",
        "class SelfAttentionBlock(nn.Module):\n",
        "    \"\"\" \n",
        "        Implementation of Self attention Block according to paper \n",
        "        'Self-Attention Generative Adversarial Networks' (https://arxiv.org/abs/1805.08318)\n",
        "        Flexible Self Attention (FSA) layer according to paper\n",
        "        Efficient Super Resolution For Large-Scale Images Using Attentional GAN (https://arxiv.org/pdf/1812.04821.pdf)\n",
        "          The FSA layer borrows the self attention layer from SAGAN, \n",
        "          and wraps it with a max-pooling layer to reduce the size \n",
        "          of the feature maps and enable large-size images to fit in memory.\n",
        "        Used in Generator and Discriminator Networks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, max_pool=False, poolsize = 4, spectral_norm=False, ret_attention=False): #in_dim = in_feature_maps\n",
        "        super(SelfAttentionBlock,self).__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.max_pool = max_pool\n",
        "        self.poolsize = poolsize\n",
        "        self.ret_attention = ret_attention\n",
        "        \n",
        "        if self.max_pool:\n",
        "            self.pooled = nn.MaxPool2d(kernel_size=self.poolsize, stride=self.poolsize) #kernel_size=4, stride=4\n",
        "            # Note: can test using strided convolutions instead of MaxPool2d! :\n",
        "            #upsample_block_num = int(math.log(scale_factor, 2))\n",
        "            #self.pooled = nn.Conv2d .... strided conv\n",
        "            # upsample_o = [UpconvBlock(in_channels=in_dim, out_channels=in_dim, upscale_factor=2, mode='bilinear', act_type='leakyrelu') for _ in range(upsample_block_num)]\n",
        "            ## upsample_o.append(nn.Conv2d(nf, in_nc, kernel_size=9, stride=1, padding=4))\n",
        "            ## self.upsample_o = nn.Sequential(*upsample_o)\n",
        "\n",
        "            # self.upsample_o = B.Upsample(scale_factor=self.poolsize, mode='bilinear', align_corners=False) \n",
        "            \n",
        "        self.conv_f = add_spectral_norm(\n",
        "            nn.Conv1d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1, padding = 0), \n",
        "            use_spectral_norm=spectral_norm) #query_conv \n",
        "        self.conv_g = add_spectral_norm(\n",
        "            nn.Conv1d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1, padding = 0), \n",
        "            use_spectral_norm=spectral_norm) #key_conv \n",
        "        self.conv_h = add_spectral_norm(\n",
        "            nn.Conv1d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1, padding = 0), \n",
        "            use_spectral_norm=spectral_norm) #value_conv \n",
        "\n",
        "        self.gamma = nn.Parameter(torch.zeros(1)) # Trainable interpolation parameter\n",
        "        self.softmax  = nn.Softmax(dim = -1)\n",
        "        \n",
        "    def forward(self,input):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                input : input feature maps( B X C X W X H)\n",
        "            returns :\n",
        "                out : self attention value + input feature \n",
        "                attention: B X N X N (N is Width*Height)\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.max_pool: #Downscale with Max Pool\n",
        "            x = self.pooled(input)\n",
        "        else:\n",
        "            x = input\n",
        "            \n",
        "        batch_size, C, width, height = x.size()\n",
        "        \n",
        "        N = width * height\n",
        "        x = x.view(batch_size, -1, N)\n",
        "        f = self.conv_f(x) #proj_query  # B X CX(N)\n",
        "        g = self.conv_g(x) #proj_key    # B X C x (*W*H)\n",
        "        h = self.conv_h(x) #proj_value  # B X C X N\n",
        "\n",
        "        s = torch.bmm(f.permute(0, 2, 1), g) # energy, transpose check\n",
        "        # get probabilities\n",
        "        attention = self.softmax(s) #beta #attention # BX (N) X (N) \n",
        "        \n",
        "        out = torch.bmm(h, attention.permute(0,2,1))\n",
        "        out = out.view(batch_size, C, width, height) \n",
        "        \n",
        "        if self.max_pool: #Upscale to original size\n",
        "            # out = self.upsample_o(out)\n",
        "            out = Upsample(size=(input.shape[2],input.shape[3]), mode='bicubic', align_corners=False)(out) #bicubic (PyTorch > 1.0) | bilinear others.\n",
        "        \n",
        "        out = self.gamma*out + input #Add original input\n",
        "        \n",
        "        if self.ret_attention:\n",
        "            return out, attention\n",
        "        else:\n",
        "            return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aUqU2np7SzUa"
      },
      "source": [
        "#@title ESRGAN_arch.py (removing if statements)\n",
        "\"\"\"\n",
        "RRDBNet_arch.py (12-2-20)\n",
        "https://github.com/victorca25/BasicSR/blob/master/codes/models/modules/architectures/RRDBNet_arch.py\n",
        "\"\"\"\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torchvision\n",
        "#from . import block as B\n",
        "import functools\n",
        "#from . import spectral_norm as SN\n",
        "\n",
        "\n",
        "####################\n",
        "# RRDBNet Generator (original architecture)\n",
        "####################\n",
        "\n",
        "class RRDBNet(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, nr=3, gc=32, upscale=4, norm_type=None, \\\n",
        "            act_type='leakyrelu', mode='CNA', upsample_mode='upconv', convtype='Conv2D', \\\n",
        "            finalact=None, gaussian_noise=False, plus=False):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        n_upscale = int(math.log(upscale, 2))\n",
        "        if upscale == 3:\n",
        "            n_upscale = 1\n",
        "\n",
        "        fea_conv = conv_block(in_nc, nf, kernel_size=3, norm_type=None, act_type=None, convtype=convtype)\n",
        "        rb_blocks = [RRDB(nf, nr, kernel_size=3, gc=32, stride=1, bias=1, pad_type='zero', \\\n",
        "            norm_type=norm_type, act_type=act_type, mode='CNA', convtype=convtype, \\\n",
        "            gaussian_noise=gaussian_noise, plus=plus) for _ in range(nb)]\n",
        "        LR_conv = conv_block(nf, nf, kernel_size=3, norm_type=norm_type, act_type=None, mode=mode, convtype=convtype)\n",
        "\n",
        "        if upsample_mode == 'upconv':\n",
        "            upsample_block = upconv_block\n",
        "        elif upsample_mode == 'pixelshuffle':\n",
        "            upsample_block = pixelshuffle_block\n",
        "        else:\n",
        "            raise NotImplementedError('upsample mode [{:s}] is not found'.format(upsample_mode))\n",
        "        if upscale == 3:\n",
        "            upsampler = upsample_block(nf, nf, 3, act_type=act_type, convtype=convtype)\n",
        "        else:\n",
        "            upsampler = [upsample_block(nf, nf, act_type=act_type, convtype=convtype) for _ in range(n_upscale)]\n",
        "        HR_conv0 = conv_block(nf, nf, kernel_size=3, norm_type=None, act_type=act_type, convtype=convtype)\n",
        "        HR_conv1 = conv_block(nf, out_nc, kernel_size=3, norm_type=None, act_type=None, convtype=convtype)\n",
        "\n",
        "        # Note: this option adds new parameters to the architecture, another option is to use \"outm\" in the forward\n",
        "        outact = act(finalact) if finalact else None\n",
        "        \n",
        "        self.model = sequential(fea_conv, ShortcutBlock(sequential(*rb_blocks, LR_conv)),\\\n",
        "            *upsampler, HR_conv0, HR_conv1, outact)\n",
        "\n",
        "    def forward(self, x,):\n",
        "        x = self.model(x)\n",
        "      \n",
        "        \"\"\"\n",
        "        if outm=='scaltanh': # limit output range to [-1,1] range with tanh and rescale to [0,1] Idea from: https://github.com/goldhuang/SRGAN-PyTorch/blob/master/model.py\n",
        "            return(torch.tanh(x) + 1.0) / 2.0\n",
        "        elif outm=='tanh': # limit output to [-1,1] range\n",
        "            return torch.tanh(x)\n",
        "        elif outm=='sigmoid': # limit output to [0,1] range\n",
        "            return torch.sigmoid(x)\n",
        "        elif outm=='clamp':\n",
        "            return torch.clamp(x, min=0.0, max=1.0)\n",
        "        else: #Default, no cap for the output\n",
        "          return x\n",
        "        \"\"\"\n",
        "        return x\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    '''\n",
        "    Residual in Residual Dense Block\n",
        "    (ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, nf, nr=3, kernel_size=3, gc=32, stride=1, bias=1, pad_type='zero', \\\n",
        "            norm_type=None, act_type='leakyrelu', mode='CNA', convtype='Conv2D', \\\n",
        "            spectral_norm=False, gaussian_noise=False, plus=False):\n",
        "        super(RRDB, self).__init__()\n",
        "        # This is for backwards compatibility with existing models\n",
        "        if nr == 3:\n",
        "            self.RDB1 = ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type, \\\n",
        "                    norm_type, act_type, mode, convtype, spectral_norm=spectral_norm, \\\n",
        "                    gaussian_noise=gaussian_noise, plus=plus)\n",
        "            self.RDB2 = ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type, \\\n",
        "                    norm_type, act_type, mode, convtype, spectral_norm=spectral_norm, \\\n",
        "                    gaussian_noise=gaussian_noise, plus=plus)\n",
        "            self.RDB3 = ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type, \\\n",
        "                    norm_type, act_type, mode, convtype, spectral_norm=spectral_norm, \\\n",
        "                    gaussian_noise=gaussian_noise, plus=plus)\n",
        "        else:\n",
        "            RDB_list = [ResidualDenseBlock_5C(nf, kernel_size, gc, stride, bias, pad_type,\n",
        "                                              norm_type, act_type, mode, convtype, spectral_norm=spectral_norm,\n",
        "                                              gaussian_noise=gaussian_noise, plus=plus) for _ in range(nr)]\n",
        "            self.RDBs = nn.Sequential(*RDB_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if hasattr(self, 'RDB1'):\n",
        "            out = self.RDB1(x)\n",
        "            out = self.RDB2(out)\n",
        "            out = self.RDB3(out)\n",
        "        else:\n",
        "            out = self.RDBs(x)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "class ResidualDenseBlock_5C(nn.Module):\n",
        "    '''\n",
        "    Residual Dense Block\n",
        "    style: 5 convs\n",
        "    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)\n",
        "    Modified options that can be used:\n",
        "        - \"Partial Convolution based Padding\" arXiv:1811.11718\n",
        "        - \"Spectral normalization\" arXiv:1802.05957\n",
        "        - \"ICASSP 2020 - ESRGAN+ : Further Improving ESRGAN\" N. C. \n",
        "            {Rakotonirina} and A. {Rasoanaivo}\n",
        "    \n",
        "    Args:\n",
        "        nf (int): Channel number of intermediate features (num_feat).\n",
        "        gc (int): Channels for each growth (num_grow_ch: growth channel, \n",
        "            i.e. intermediate channels).\n",
        "        convtype (str): the type of convolution to use. Default: 'Conv2D'\n",
        "        gaussian_noise (bool): enable the ESRGAN+ gaussian noise (no new \n",
        "            trainable parameters)\n",
        "        plus (bool): enable the additional residual paths from ESRGAN+ \n",
        "            (adds trainable parameters)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, nf=64, kernel_size=3, gc=32, stride=1, bias=1, pad_type='zero', \\\n",
        "            norm_type=None, act_type='leakyrelu', mode='CNA', convtype='Conv2D', \\\n",
        "            spectral_norm=False, gaussian_noise=False, plus=False):\n",
        "        super(ResidualDenseBlock_5C, self).__init__()\n",
        "        \n",
        "        ## +\n",
        "        self.noise = GaussianNoise() if gaussian_noise else None\n",
        "        self.conv1x1 = conv1x1(nf, gc) if plus else None\n",
        "        ## +\n",
        "\n",
        "        self.conv1 = conv_block(nf, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        self.conv2 = conv_block(nf+gc, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        self.conv3 = conv_block(nf+2*gc, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        self.conv4 = conv_block(nf+3*gc, gc, kernel_size, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=act_type, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "        if mode == 'CNA':\n",
        "            last_act = None\n",
        "        else:\n",
        "            last_act = act_type\n",
        "        self.conv5 = conv_block(nf+4*gc, nf, 3, stride, bias=bias, pad_type=pad_type, \\\n",
        "            norm_type=norm_type, act_type=last_act, mode=mode, convtype=convtype, \\\n",
        "            spectral_norm=spectral_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.conv2(torch.cat((x, x1), 1))\n",
        "        \"\"\"\n",
        "        if self.conv1x1:\n",
        "            x2 = x2 + self.conv1x1(x) #+\n",
        "        \"\"\"\n",
        "        x3 = self.conv3(torch.cat((x, x1, x2), 1))\n",
        "        x4 = self.conv4(torch.cat((x, x1, x2, x3), 1))\n",
        "        \"\"\"\n",
        "        if self.conv1x1:\n",
        "            x4 = x4 + x2 #+\n",
        "        \"\"\"\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        \"\"\"\n",
        "        if self.noise:\n",
        "            return self.noise(x5.mul(0.2) + x)\n",
        "        \"\"\"\n",
        "        #else:\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "####################\n",
        "# RRDBNet Generator (modified/\"new\" architecture)\n",
        "####################\n",
        "\n",
        "\n",
        "class MRRDBNet(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, gc=32):\n",
        "        super(MRRDBNet, self).__init__()\n",
        "        RRDB_block_f = functools.partial(RRDBM, nf=nf, gc=gc)\n",
        "\n",
        "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
        "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        #### upsampling\n",
        "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fea = self.conv_first(x)\n",
        "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
        "        fea = fea + trunk\n",
        "\n",
        "        fea = self.lrelu(self.upconv1(torch.nn.functional.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        fea = self.lrelu(self.upconv2(torch.nn.functional.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResidualDenseBlock_5CM(nn.Module):\n",
        "    '''\n",
        "    Residual Dense Block\n",
        "    '''\n",
        "    def __init__(self, nf=64, gc=32, bias=True):\n",
        "        super(ResidualDenseBlock_5CM, self).__init__()\n",
        "        # gc: growth channel, i.e. intermediate channels\n",
        "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        # initialization\n",
        "        default_init_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], scale=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "class RRDBM(nn.Module):\n",
        "    '''Residual in Residual Dense Block'''\n",
        "\n",
        "    def __init__(self, nf, gc=32):\n",
        "        super(RRDBM, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock_5CM(nf, gc)\n",
        "        self.RDB2 = ResidualDenseBlock_5CM(nf, gc)\n",
        "        self.RDB3 = ResidualDenseBlock_5CM(nf, gc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "        return out * 0.2 + x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jY_7XniVQk8y"
      },
      "source": [
        "model_path = '/content/4x_cat_patch_325000_G.pth' #@param\n",
        "state_dict = torch.load(model_path)\n",
        "model = torch.jit.script(RRDBNet(in_nc=3, out_nc=3, nf=64, nb=23, gc=32, upscale=4, norm_type='null',\n",
        "            act_type='leakyrelu', mode='CNA', upsample_mode='upconv', convtype='Conv2D',\n",
        "            finalact=None, gaussian_noise=False, plus=False, \n",
        "            nr=3))\n",
        "\n",
        "image_path = \"/content/image.png\" #@param\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = torch.from_numpy(image).unsqueeze(0).permute(0,3,1,2)/255\n",
        "\n",
        "#for k, v in state_dict.items():\n",
        "#  print(k)\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "model = model.eval()\n",
        "\n",
        "#out = model(torch.randn(1, 3, 64, 64))\n",
        "out = model(image)\n",
        "print(out.shape)\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "save_image(out, \"out.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
